
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>keras.callbacks &#8212; pysparkdl  documentation</title>
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pysparkdl.css" type="text/css" />
    
    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/pysparkdl.js"></script>
    
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
    
        <li class="nav-item nav-item-0"><a href="../../index.html">pysparkdl  documentation</a> &#187;</li>

          <li class="nav-item nav-item-1"><a href="../index.html" accesskey="U">Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">keras.callbacks</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for keras.callbacks</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2015 The TensorFlow Authors. All Rights Reserved.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1"># ==============================================================================</span>
<span class="c1"># pylint: disable=g-import-not-at-top</span>
<span class="c1"># pylint: disable=g-classes-have-attributes</span>
<span class="sd">&quot;&quot;&quot;Callbacks: utilities called at certain points during model training.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">tensorflow.compat.v2</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">backend</span>
<span class="kn">from</span> <span class="nn">keras.distribute</span> <span class="kn">import</span> <span class="n">distributed_file_utils</span>
<span class="kn">from</span> <span class="nn">keras.distribute</span> <span class="kn">import</span> <span class="n">worker_training_state</span>
<span class="kn">from</span> <span class="nn">keras.optimizer_v2</span> <span class="kn">import</span> <span class="n">learning_rate_schedule</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">generic_utils</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">tf_utils</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">version_utils</span>
<span class="kn">from</span> <span class="nn">keras.utils.data_utils</span> <span class="kn">import</span> <span class="n">Sequence</span>
<span class="kn">from</span> <span class="nn">keras.utils.generic_utils</span> <span class="kn">import</span> <span class="n">Progbar</span>
<span class="kn">from</span> <span class="nn">keras.utils.io_utils</span> <span class="kn">import</span> <span class="n">path_to_string</span>
<span class="kn">from</span> <span class="nn">keras.utils.mode_keys</span> <span class="kn">import</span> <span class="n">ModeKeys</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.platform</span> <span class="kn">import</span> <span class="n">tf_logging</span> <span class="k">as</span> <span class="n">logging</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.util.tf_export</span> <span class="kn">import</span> <span class="n">keras_export</span>
<span class="kn">from</span> <span class="nn">tensorflow.tools.docs</span> <span class="kn">import</span> <span class="n">doc_controls</span>

<span class="k">try</span><span class="p">:</span>
  <span class="kn">import</span> <span class="nn">requests</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
  <span class="n">requests</span> <span class="o">=</span> <span class="kc">None</span>


<span class="c1"># Note: `configure_callbacks` is only used in TF1.</span>
<span class="k">def</span> <span class="nf">configure_callbacks</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span>
                        <span class="n">model</span><span class="p">,</span>
                        <span class="n">do_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">count_mode</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">,</span>
                        <span class="n">mode</span><span class="o">=</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Configures callbacks for use in various training loops.</span>

<span class="sd">  Args:</span>
<span class="sd">      callbacks: List of Callbacks.</span>
<span class="sd">      model: Model being trained.</span>
<span class="sd">      do_validation: Whether or not validation loop will be run.</span>
<span class="sd">      batch_size: Number of samples per batch.</span>
<span class="sd">      epochs: Number of epoch to train.</span>
<span class="sd">      steps_per_epoch: Number of batches to run per training epoch.</span>
<span class="sd">      samples: Number of training samples.</span>
<span class="sd">      verbose: int, 0 or 1. Keras logging verbosity to pass to ProgbarLogger.</span>
<span class="sd">      count_mode: One of &#39;steps&#39; or &#39;samples&#39;. Per-batch or per-sample count.</span>
<span class="sd">      mode: String. One of ModeKeys.TRAIN, ModeKeys.TEST, or ModeKeys.PREDICT.</span>
<span class="sd">        Which loop mode to configure callbacks for.</span>

<span class="sd">  Returns:</span>
<span class="sd">      Instance of CallbackList used to control all Callbacks.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="c1"># Check if callbacks have already been configured.</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">callbacks</span><span class="p">,</span> <span class="n">CallbackList</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">callbacks</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">callbacks</span><span class="p">:</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="c1"># Add additional callbacks during training.</span>
  <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="n">History</span><span class="p">()</span>
    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">BaseLogger</span><span class="p">()]</span> <span class="o">+</span> <span class="p">(</span><span class="n">callbacks</span> <span class="ow">or</span> <span class="p">[])</span> <span class="o">+</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">history</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
      <span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ProgbarLogger</span><span class="p">(</span><span class="n">count_mode</span><span class="p">))</span>
  <span class="n">callback_list</span> <span class="o">=</span> <span class="n">CallbackList</span><span class="p">(</span><span class="n">callbacks</span><span class="p">)</span>

  <span class="c1"># Set callback model</span>
  <span class="n">callback_model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">_get_callback_model</span><span class="p">()</span>  <span class="c1"># pylint: disable=protected-access</span>
  <span class="n">callback_list</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">callback_model</span><span class="p">)</span>

  <span class="n">set_callback_parameters</span><span class="p">(</span>
      <span class="n">callback_list</span><span class="p">,</span>
      <span class="n">model</span><span class="p">,</span>
      <span class="n">do_validation</span><span class="o">=</span><span class="n">do_validation</span><span class="p">,</span>
      <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
      <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
      <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">steps_per_epoch</span><span class="p">,</span>
      <span class="n">samples</span><span class="o">=</span><span class="n">samples</span><span class="p">,</span>
      <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
      <span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span>

  <span class="n">callback_list</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">False</span>
  <span class="k">return</span> <span class="n">callback_list</span>


<span class="k">def</span> <span class="nf">set_callback_parameters</span><span class="p">(</span><span class="n">callback_list</span><span class="p">,</span>
                            <span class="n">model</span><span class="p">,</span>
                            <span class="n">do_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                            <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">epochs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">steps_per_epoch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">samples</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                            <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">mode</span><span class="o">=</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Sets callback parameters.</span>

<span class="sd">  Args:</span>
<span class="sd">      callback_list: CallbackList instance.</span>
<span class="sd">      model: Model being trained.</span>
<span class="sd">      do_validation: Whether or not validation loop will be run.</span>
<span class="sd">      batch_size: Number of samples per batch.</span>
<span class="sd">      epochs: Number of epoch to train.</span>
<span class="sd">      steps_per_epoch: Number of batches to run per training epoch.</span>
<span class="sd">      samples: Number of training samples.</span>
<span class="sd">      verbose: int, 0 or 1. Keras logging verbosity to pass to ProgbarLogger.</span>
<span class="sd">      mode: String. One of ModeKeys.TRAIN, ModeKeys.TEST, or ModeKeys.PREDICT.</span>
<span class="sd">        Which loop mode to configure callbacks for.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">metric_names</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span>
  <span class="k">for</span> <span class="n">cbk</span> <span class="ow">in</span> <span class="n">callback_list</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cbk</span><span class="p">,</span> <span class="p">(</span><span class="n">BaseLogger</span><span class="p">,</span> <span class="n">ProgbarLogger</span><span class="p">)):</span>
      <span class="n">cbk</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="n">metric_names</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>  <span class="c1"># Exclude `loss`</span>

  <span class="c1"># Set callback parameters</span>
  <span class="n">callback_metrics</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="c1"># When we have deferred build scenario with iterator input, we will compile</span>
  <span class="c1"># when we standardize first batch of data.</span>
  <span class="k">if</span> <span class="n">mode</span> <span class="o">!=</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span><span class="p">:</span>
    <span class="n">callback_metrics</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">metric_names</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">do_validation</span><span class="p">:</span>
      <span class="n">callback_metrics</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;val_&#39;</span> <span class="o">+</span> <span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">metric_names</span><span class="p">]</span>
  <span class="n">callback_params</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
      <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="n">epochs</span><span class="p">,</span>
      <span class="s1">&#39;steps&#39;</span><span class="p">:</span> <span class="n">steps_per_epoch</span><span class="p">,</span>
      <span class="s1">&#39;samples&#39;</span><span class="p">:</span> <span class="n">samples</span><span class="p">,</span>
      <span class="s1">&#39;verbose&#39;</span><span class="p">:</span> <span class="n">verbose</span><span class="p">,</span>
      <span class="s1">&#39;do_validation&#39;</span><span class="p">:</span> <span class="n">do_validation</span><span class="p">,</span>
      <span class="s1">&#39;metrics&#39;</span><span class="p">:</span> <span class="n">callback_metrics</span><span class="p">,</span>
  <span class="p">}</span>
  <span class="n">callback_list</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">callback_params</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_is_generator_like</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Checks if data is a generator, Sequence, or Iterator.&quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;__next__&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="s1">&#39;next&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span>
      <span class="n">data</span><span class="p">,</span> <span class="p">(</span><span class="n">Sequence</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Iterator</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Iterator</span><span class="p">)))</span>


<span class="k">def</span> <span class="nf">make_logs</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">logs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Computes logs for sending to `on_batch_end` methods.&quot;&quot;&quot;</span>
  <span class="n">metric_names</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">metrics_names</span>
  <span class="k">if</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">{</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">}</span> <span class="ow">and</span> <span class="n">metric_names</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">output</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">metric_names</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
      <span class="n">logs</span><span class="p">[</span><span class="n">prefix</span> <span class="o">+</span> <span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">output</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">logs</span><span class="p">[</span><span class="s1">&#39;outputs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">outputs</span>
  <span class="k">return</span> <span class="n">logs</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.CallbackList&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">CallbackList</span><span class="p">:</span>
  <span class="sd">&quot;&quot;&quot;Container abstracting a list of callbacks.&quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">callbacks</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">add_history</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">add_progbar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">model</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">params</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Container for `Callback` instances.</span>

<span class="sd">    This object wraps a list of `Callback` instances, making it possible</span>
<span class="sd">    to call them all at once via a single endpoint</span>
<span class="sd">    (e.g. `callback_list.on_epoch_end(...)`).</span>

<span class="sd">    Args:</span>
<span class="sd">      callbacks: List of `Callback` instances.</span>
<span class="sd">      add_history: Whether a `History` callback should be added, if one does not</span>
<span class="sd">        already exist in the `callbacks` list.</span>
<span class="sd">      add_progbar: Whether a `ProgbarLogger` callback should be added, if one</span>
<span class="sd">        does not already exist in the `callbacks` list.</span>
<span class="sd">      model: The `Model` these callbacks are used with.</span>
<span class="sd">      **params: If provided, parameters will be passed to each `Callback` via</span>
<span class="sd">        `Callback.set_params`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">callbacks</span><span class="p">)</span> <span class="k">if</span> <span class="n">callbacks</span> <span class="k">else</span> <span class="p">[]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_add_default_callbacks</span><span class="p">(</span><span class="n">add_history</span><span class="p">,</span> <span class="n">add_progbar</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">model</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">params</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="c1"># Performance optimization: determines if batch hooks need to be called.</span>
    <span class="c1"># pylint: disable=protected-access</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span> <span class="o">=</span> <span class="nb">all</span><span class="p">(</span>
        <span class="nb">getattr</span><span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="s1">&#39;_supports_tf_logs&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_batch_hooks_support_tf_logs</span> <span class="o">=</span> <span class="nb">all</span><span class="p">(</span>
        <span class="nb">getattr</span><span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="s1">&#39;_supports_tf_logs&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span>
        <span class="k">if</span> <span class="n">cb</span><span class="o">.</span><span class="n">_implements_train_batch_hooks</span><span class="p">()</span> <span class="ow">or</span> <span class="n">cb</span>
        <span class="o">.</span><span class="n">_implements_test_batch_hooks</span><span class="p">()</span> <span class="ow">or</span> <span class="n">cb</span><span class="o">.</span><span class="n">_implements_predict_batch_hooks</span><span class="p">())</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_train_batch_hooks</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
        <span class="n">cb</span><span class="o">.</span><span class="n">_implements_train_batch_hooks</span><span class="p">()</span> <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_test_batch_hooks</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
        <span class="n">cb</span><span class="o">.</span><span class="n">_implements_test_batch_hooks</span><span class="p">()</span> <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_predict_batch_hooks</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
        <span class="n">cb</span><span class="o">.</span><span class="n">_implements_predict_batch_hooks</span><span class="p">()</span> <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">)</span>
    <span class="c1"># pylint: enable=protected-access</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_disallow_batch_hooks_in_ps_strategy</span><span class="p">()</span>

    <span class="c1"># Performance check: Check batch hooks for slowness compared to batch time.</span>
    <span class="c1"># Only run check for custom callbacks (i.e. not present in this file).</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_check_timing</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
        <span class="n">cbk</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">globals</span><span class="p">()</span> <span class="k">for</span> <span class="n">cbk</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_num_batches_for_timing_check</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_time</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_batch_times</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">def</span> <span class="nf">_add_default_callbacks</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">add_history</span><span class="p">,</span> <span class="n">add_progbar</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Adds `Callback`s that are always present.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_progbar</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="n">ProgbarLogger</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_progbar</span> <span class="o">=</span> <span class="n">cb</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="n">History</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="o">=</span> <span class="n">cb</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_progbar</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">add_progbar</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_progbar</span> <span class="o">=</span> <span class="n">ProgbarLogger</span><span class="p">(</span><span class="n">count_mode</span><span class="o">=</span><span class="s1">&#39;steps&#39;</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_progbar</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">add_history</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_history</span> <span class="o">=</span> <span class="n">History</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_process_logs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="p">,</span> <span class="n">is_batch_hook</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Turns tensors into numpy arrays or Python scalars if necessary.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">logs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">logs</span>
    <span class="k">if</span> <span class="n">is_batch_hook</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_hooks_support_tf_logs</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">logs</span>
    <span class="k">return</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">append</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">callback</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">callback</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span><span class="p">:</span>
      <span class="n">model</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_history</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">set_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_call_batch_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">hook</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper function for all batch_{begin | end} methods.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="k">return</span>

    <span class="k">if</span> <span class="n">hook</span> <span class="o">==</span> <span class="s1">&#39;begin&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_begin_hook</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">hook</span> <span class="o">==</span> <span class="s1">&#39;end&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_end_hook</span><span class="p">(</span><span class="n">mode</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unrecognized hook: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">hook</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">_call_batch_begin_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper function for `on_*_batch_begin` methods.&quot;&quot;&quot;</span>
    <span class="n">hook_name</span> <span class="o">=</span> <span class="s1">&#39;on_</span><span class="si">{mode}</span><span class="s1">_batch_begin&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook_helper</span><span class="p">(</span><span class="n">hook_name</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_timing</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_call_batch_end_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper function for `on_*_batch_end` methods.&quot;&quot;&quot;</span>
    <span class="n">hook_name</span> <span class="o">=</span> <span class="s1">&#39;on_</span><span class="si">{mode}</span><span class="s1">_batch_end&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_timing</span> <span class="ow">and</span> <span class="n">batch</span> <span class="o">&gt;=</span> <span class="mi">1</span><span class="p">:</span>
      <span class="n">batch_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_time</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_batch_times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">batch_time</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook_helper</span><span class="p">(</span><span class="n">hook_name</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_times</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_batches_for_timing_check</span><span class="p">:</span>
      <span class="n">end_hook_name</span> <span class="o">=</span> <span class="n">hook_name</span>
      <span class="n">begin_hook_name</span> <span class="o">=</span> <span class="s1">&#39;on_</span><span class="si">{mode}</span><span class="s1">_batch_begin&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="n">mode</span><span class="p">)</span>
      <span class="n">avg_batch_time</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_times</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_batch_times</span><span class="p">)</span>
      <span class="n">avg_end_hook_time</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span><span class="p">[</span><span class="n">end_hook_name</span><span class="p">])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span><span class="p">[</span><span class="n">end_hook_name</span><span class="p">])</span>
      <span class="n">avg_begin_hook_time</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span><span class="p">[</span><span class="n">begin_hook_name</span><span class="p">])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span><span class="p">[</span><span class="n">begin_hook_name</span><span class="p">])</span>

      <span class="n">threshold_time</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">avg_batch_time</span>
      <span class="n">warning_msg</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;Callback method `</span><span class="si">{hook}</span><span class="s1">` is slow compared to &#39;</span>
                     <span class="s1">&#39;the batch time (batch time: </span><span class="si">{batch_time:.4f}</span><span class="s1">s vs &#39;</span>
                     <span class="s1">&#39;`</span><span class="si">{hook}</span><span class="s1">` time: </span><span class="si">{hook_time:.4f}</span><span class="s1">s). Check your callbacks.&#39;</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">avg_begin_hook_time</span> <span class="o">&gt;</span> <span class="n">threshold_time</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">warning_msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">hook</span><span class="o">=</span><span class="n">begin_hook_name</span><span class="p">,</span>
            <span class="n">batch_time</span><span class="o">=</span><span class="n">avg_batch_time</span><span class="p">,</span>
            <span class="n">hook_time</span><span class="o">=</span><span class="n">avg_begin_hook_time</span><span class="p">))</span>
      <span class="k">if</span> <span class="n">avg_end_hook_time</span> <span class="o">&gt;</span> <span class="n">threshold_time</span><span class="p">:</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="n">warning_msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">hook</span><span class="o">=</span><span class="n">end_hook_name</span><span class="p">,</span>
            <span class="n">batch_time</span><span class="o">=</span><span class="n">avg_batch_time</span><span class="p">,</span>
            <span class="n">hook_time</span><span class="o">=</span><span class="n">avg_end_hook_time</span><span class="p">))</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_check_timing</span> <span class="o">=</span> <span class="kc">False</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_time</span> <span class="o">=</span> <span class="kc">None</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_batch_times</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span> <span class="o">=</span> <span class="p">{}</span>

  <span class="k">def</span> <span class="nf">_call_batch_hook_helper</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper function for `on_*_batch_*` methods.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_timing</span><span class="p">:</span>
      <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="n">is_batch_hook</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">hook</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="n">hook_name</span><span class="p">)</span>
      <span class="n">hook</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_timing</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">hook_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span><span class="p">[</span><span class="n">hook_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_hook_times</span><span class="p">[</span><span class="n">hook_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_call_begin_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper function for on_{train|test|predict}_begin methods.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_test_begin</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_predict_begin</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_call_end_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Helper function for on_{train|test|predict}_end methods.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_test_end</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_predict_end</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_train_batch_hooks</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s1">&#39;begin&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_train_batch_hooks</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s1">&#39;end&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_epoch_begin` methods of its callbacks.</span>

<span class="sd">    This function should only be called during TRAIN mode.</span>

<span class="sd">    Args:</span>
<span class="sd">        epoch: Integer, index of epoch.</span>
<span class="sd">        logs: Dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_epoch_begin</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_epoch_end` methods of its callbacks.</span>

<span class="sd">    This function should only be called during TRAIN mode.</span>

<span class="sd">    Args:</span>
<span class="sd">        epoch: Integer, index of epoch.</span>
<span class="sd">        logs: Dict, metric results for this training epoch, and for the</span>
<span class="sd">          validation epoch if validation is performed. Validation result keys</span>
<span class="sd">          are prefixed with `val_`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_epoch_end</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_train_batch_begin` methods of its callbacks.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch: Integer, index of batch within the current epoch.</span>
<span class="sd">        logs: Dict, contains the return value of `model.train_step`. Typically,</span>
<span class="sd">          the values of the `Model`&#39;s metrics are returned.  Example:</span>
<span class="sd">          `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_train_batch_hooks</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s1">&#39;begin&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_train_batch_end` methods of its callbacks.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch: Integer, index of batch within the current epoch.</span>
<span class="sd">        logs: Dict. Aggregated metric results up until this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_train_batch_hooks</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TRAIN</span><span class="p">,</span> <span class="s1">&#39;end&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_test_batch_begin` methods of its callbacks.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch: Integer, index of batch within the current epoch.</span>
<span class="sd">        logs: Dict, contains the return value of `model.test_step`. Typically,</span>
<span class="sd">          the values of the `Model`&#39;s metrics are returned.  Example:</span>
<span class="sd">          `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;: 0.7}`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_test_batch_hooks</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">,</span> <span class="s1">&#39;begin&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_test_batch_end` methods of its callbacks.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch: Integer, index of batch within the current epoch.</span>
<span class="sd">        logs: Dict. Aggregated metric results up until this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_test_batch_hooks</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">TEST</span><span class="p">,</span> <span class="s1">&#39;end&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_predict_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_predict_batch_begin` methods of its callbacks.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch: Integer, index of batch within the current epoch.</span>
<span class="sd">        logs: Dict, contains the return value of `model.predict_step`,</span>
<span class="sd">          it typically returns a dict with a key &#39;outputs&#39; containing</span>
<span class="sd">          the model&#39;s outputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_predict_batch_hooks</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span><span class="p">,</span> <span class="s1">&#39;begin&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_predict_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_predict_batch_end` methods of its callbacks.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch: Integer, index of batch within the current epoch.</span>
<span class="sd">        logs: Dict. Aggregated metric results up until this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_call_predict_batch_hooks</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hook</span><span class="p">(</span><span class="n">ModeKeys</span><span class="o">.</span><span class="n">PREDICT</span><span class="p">,</span> <span class="s1">&#39;end&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_train_begin` methods of its callbacks.</span>

<span class="sd">    Args:</span>
<span class="sd">        logs: Dict. Currently, no data is passed via this argument</span>
<span class="sd">          for this method, but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_train_begin</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_train_end` methods of its callbacks.</span>

<span class="sd">    Args:</span>
<span class="sd">        logs: Dict. Currently, no data is passed via this argument</span>
<span class="sd">          for this method, but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_train_end</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_test_begin` methods of its callbacks.</span>

<span class="sd">    Args:</span>
<span class="sd">        logs: Dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_test_begin</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_test_end` methods of its callbacks.</span>

<span class="sd">    Args:</span>
<span class="sd">        logs: Dict. Currently, no data is passed via this argument</span>
<span class="sd">          for this method, but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_test_end</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_predict_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the &#39;on_predict_begin` methods of its callbacks.</span>

<span class="sd">    Args:</span>
<span class="sd">        logs: Dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_predict_begin</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_predict_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calls the `on_predict_end` methods of its callbacks.</span>

<span class="sd">    Args:</span>
<span class="sd">        logs: Dict. Currently, no data is passed via this argument</span>
<span class="sd">          for this method, but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_logs</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
      <span class="n">callback</span><span class="o">.</span><span class="n">on_predict_end</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_disallow_batch_hooks_in_ps_strategy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Error out if batch-level callbacks are passed with PSStrategy.&quot;&quot;&quot;</span>
    <span class="c1"># pylint: disable=protected-access</span>
    <span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">get_strategy</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">strategy</span><span class="o">.</span><span class="n">_should_use_with_coordinator</span><span class="p">:</span>
      <span class="n">unsupported_callbacks</span> <span class="o">=</span> <span class="p">[]</span>
      <span class="k">for</span> <span class="n">cb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">callbacks</span><span class="p">:</span>
        <span class="c1"># These Callbacks can accept RemoteValues directly.</span>
        <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">cb</span><span class="p">,</span> <span class="s1">&#39;_supports_tf_logs&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
          <span class="k">continue</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">cb</span><span class="o">.</span><span class="n">_implements_train_batch_hooks</span><span class="p">()</span> <span class="ow">or</span>
            <span class="n">cb</span><span class="o">.</span><span class="n">_implements_test_batch_hooks</span><span class="p">()</span> <span class="ow">or</span>
            <span class="n">cb</span><span class="o">.</span><span class="n">_implements_predict_batch_hooks</span><span class="p">()):</span>
          <span class="n">unsupported_callbacks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cb</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">unsupported_callbacks</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Batch-level `Callback`s are not supported with &#39;</span>
                         <span class="s1">&#39;`ParameterServerStrategy`. Found unsupported &#39;</span>
                         <span class="s1">&#39;callbacks: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">unsupported_callbacks</span><span class="p">))</span>
    <span class="c1"># pylint: enable=protected-access</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.Callback&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">Callback</span><span class="p">:</span>
  <span class="sd">&quot;&quot;&quot;Abstract base class used to build new callbacks.</span>

<span class="sd">  Callbacks can be passed to keras methods such as `fit`, `evaluate`, and</span>
<span class="sd">  `predict` in order to hook into the various stages of the model training and</span>
<span class="sd">  inference lifecycle.</span>

<span class="sd">  To create a custom callback, subclass `keras.callbacks.Callback` and override</span>
<span class="sd">  the method associated with the stage of interest. See</span>
<span class="sd">  https://www.tensorflow.org/guide/keras/custom_callback for more information.</span>

<span class="sd">  Example:</span>

<span class="sd">  &gt;&gt;&gt; training_finished = False</span>
<span class="sd">  &gt;&gt;&gt; class MyCallback(tf.keras.callbacks.Callback):</span>
<span class="sd">  ...   def on_train_end(self, logs=None):</span>
<span class="sd">  ...     global training_finished</span>
<span class="sd">  ...     training_finished = True</span>
<span class="sd">  &gt;&gt;&gt; model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=(1,))])</span>
<span class="sd">  &gt;&gt;&gt; model.compile(loss=&#39;mean_squared_error&#39;)</span>
<span class="sd">  &gt;&gt;&gt; model.fit(tf.constant([[1.0]]), tf.constant([[1.0]]),</span>
<span class="sd">  ...           callbacks=[MyCallback()])</span>
<span class="sd">  &gt;&gt;&gt; assert training_finished == True</span>

<span class="sd">  If you want to use `Callback` objects in a custom training loop:</span>

<span class="sd">  1. You should pack all your callbacks into a single `callbacks.CallbackList`</span>
<span class="sd">     so they can all be called together.</span>
<span class="sd">  2. You will need to manually call all the `on_*` methods at the apropriate</span>
<span class="sd">     locations in your loop. Like this:</span>

<span class="sd">     ```</span>
<span class="sd">     callbacks =  tf.keras.callbacks.CallbackList([...])</span>
<span class="sd">     callbacks.append(...)</span>

<span class="sd">     callbacks.on_train_begin(...)</span>
<span class="sd">     for epoch in range(EPOCHS):</span>
<span class="sd">       callbacks.on_epoch_begin(epoch)</span>
<span class="sd">       for i, data in dataset.enumerate():</span>
<span class="sd">         callbacks.on_train_batch_begin(i)</span>
<span class="sd">         batch_logs = model.train_step(data)</span>
<span class="sd">         callbacks.on_train_batch_end(i, batch_logs)</span>
<span class="sd">       epoch_logs = ...</span>
<span class="sd">       callbacks.on_epoch_end(epoch, epoch_logs)</span>
<span class="sd">     final_logs=...</span>
<span class="sd">     callbacks.on_train_end(final_logs)</span>
<span class="sd">     ```</span>

<span class="sd">  Attributes:</span>
<span class="sd">      params: Dict. Training parameters</span>
<span class="sd">          (eg. verbosity, batch size, number of epochs...).</span>
<span class="sd">      model: Instance of `keras.models.Model`.</span>
<span class="sd">          Reference of the model being trained.</span>

<span class="sd">  The `logs` dictionary that callback methods</span>
<span class="sd">  take as argument will contain keys for quantities relevant to</span>
<span class="sd">  the current batch or epoch (see method-specific docstrings).</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">validation_data</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># pylint: disable=g-missing-from-attributes</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="c1"># Whether this Callback should only run on the chief worker in a</span>
    <span class="c1"># Multi-Worker setting.</span>
    <span class="c1"># TODO(omalleyt): Make this attr public once solution is stable.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_chief_worker_only</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>

  <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
  <span class="k">def</span> <span class="nf">on_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A backwards compatibility alias for `on_train_batch_begin`.&quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A backwards compatibility alias for `on_train_batch_end`.&quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the start of an epoch.</span>

<span class="sd">    Subclasses should override for any actions to run. This function should only</span>
<span class="sd">    be called during TRAIN mode.</span>

<span class="sd">    Args:</span>
<span class="sd">        epoch: Integer, index of epoch.</span>
<span class="sd">        logs: Dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of an epoch.</span>

<span class="sd">    Subclasses should override for any actions to run. This function should only</span>
<span class="sd">    be called during TRAIN mode.</span>

<span class="sd">    Args:</span>
<span class="sd">        epoch: Integer, index of epoch.</span>
<span class="sd">        logs: Dict, metric results for this training epoch, and for the</span>
<span class="sd">          validation epoch if validation is performed. Validation result keys</span>
<span class="sd">          are prefixed with `val_`. For training epoch, the values of the</span>
<span class="sd">         `Model`&#39;s metrics are returned. Example : `{&#39;loss&#39;: 0.2, &#39;accuracy&#39;:</span>
<span class="sd">           0.7}`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
  <span class="k">def</span> <span class="nf">on_train_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of a training batch in `fit` methods.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Note that if the `steps_per_execution` argument to `compile` in</span>
<span class="sd">    `tf.keras.Model` is set to `N`, this method will only be called every `N`</span>
<span class="sd">    batches.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch: Integer, index of batch within the current epoch.</span>
<span class="sd">        logs: Dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># For backwards compatibility.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_begin</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
  <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of a training batch in `fit` methods.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Note that if the `steps_per_execution` argument to `compile` in</span>
<span class="sd">    `tf.keras.Model` is set to `N`, this method will only be called every `N`</span>
<span class="sd">    batches.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch: Integer, index of batch within the current epoch.</span>
<span class="sd">        logs: Dict. Aggregated metric results up until this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># For backwards compatibility.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_end</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
  <span class="k">def</span> <span class="nf">on_test_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of a batch in `evaluate` methods.</span>

<span class="sd">    Also called at the beginning of a validation batch in the `fit`</span>
<span class="sd">    methods, if validation data is provided.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Note that if the `steps_per_execution` argument to `compile` in</span>
<span class="sd">    `tf.keras.Model` is set to `N`, this method will only be called every `N`</span>
<span class="sd">    batches.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch: Integer, index of batch within the current epoch.</span>
<span class="sd">        logs: Dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
  <span class="k">def</span> <span class="nf">on_test_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of a batch in `evaluate` methods.</span>

<span class="sd">    Also called at the end of a validation batch in the `fit`</span>
<span class="sd">    methods, if validation data is provided.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Note that if the `steps_per_execution` argument to `compile` in</span>
<span class="sd">    `tf.keras.Model` is set to `N`, this method will only be called every `N`</span>
<span class="sd">    batches.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch: Integer, index of batch within the current epoch.</span>
<span class="sd">        logs: Dict. Aggregated metric results up until this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
  <span class="k">def</span> <span class="nf">on_predict_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of a batch in `predict` methods.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Note that if the `steps_per_execution` argument to `compile` in</span>
<span class="sd">    `tf.keras.Model` is set to `N`, this method will only be called every `N`</span>
<span class="sd">    batches.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch: Integer, index of batch within the current epoch.</span>
<span class="sd">        logs: Dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="nd">@generic_utils</span><span class="o">.</span><span class="n">default</span>
  <span class="k">def</span> <span class="nf">on_predict_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of a batch in `predict` methods.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Note that if the `steps_per_execution` argument to `compile` in</span>
<span class="sd">    `tf.keras.Model` is set to `N`, this method will only be called every `N`</span>
<span class="sd">    batches.</span>

<span class="sd">    Args:</span>
<span class="sd">        batch: Integer, index of batch within the current epoch.</span>
<span class="sd">        logs: Dict. Aggregated metric results up until this batch.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of training.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Args:</span>
<span class="sd">        logs: Dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of training.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Args:</span>
<span class="sd">        logs: Dict. Currently the output of the last call to `on_epoch_end()`</span>
<span class="sd">          is passed to this argument for this method but that may change in</span>
<span class="sd">          the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_test_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of evaluation or validation.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Args:</span>
<span class="sd">        logs: Dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_test_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of evaluation or validation.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Args:</span>
<span class="sd">        logs: Dict. Currently the output of the last call to</span>
<span class="sd">          `on_test_batch_end()` is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_predict_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the beginning of prediction.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Args:</span>
<span class="sd">        logs: Dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="nd">@doc_controls</span><span class="o">.</span><span class="n">for_subclass_implementers</span>
  <span class="k">def</span> <span class="nf">on_predict_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Called at the end of prediction.</span>

<span class="sd">    Subclasses should override for any actions to run.</span>

<span class="sd">    Args:</span>
<span class="sd">        logs: Dict. Currently no data is passed to this argument for this method</span>
<span class="sd">          but that may change in the future.</span>
<span class="sd">    &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="nf">_implements_train_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Determines if this Callback should be called for each train batch.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">on_batch_begin</span><span class="p">)</span> <span class="ow">or</span>
            <span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">on_batch_end</span><span class="p">)</span> <span class="ow">or</span>
            <span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">on_train_batch_begin</span><span class="p">)</span> <span class="ow">or</span>
            <span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">on_train_batch_end</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">_implements_test_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Determines if this Callback should be called for each test batch.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">on_test_batch_begin</span><span class="p">)</span> <span class="ow">or</span>
            <span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">on_test_batch_end</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">_implements_predict_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Determines if this Callback should be called for each predict batch.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">(</span><span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">on_predict_batch_begin</span><span class="p">)</span> <span class="ow">or</span>
            <span class="ow">not</span> <span class="n">generic_utils</span><span class="o">.</span><span class="n">is_default</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">on_predict_batch_end</span><span class="p">))</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.BaseLogger&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">BaseLogger</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback that accumulates epoch averages of metrics.</span>

<span class="sd">  This callback is automatically applied to every Keras model.</span>

<span class="sd">  Args:</span>
<span class="sd">      stateful_metrics: Iterable of string names of metrics that</span>
<span class="sd">          should *not* be averaged over an epoch.</span>
<span class="sd">          Metrics in this list will be logged as-is in `on_epoch_end`.</span>
<span class="sd">          All others will be averaged in `on_epoch_end`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stateful_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BaseLogger</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stateful_metrics</span> <span class="ow">or</span> <span class="p">[])</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">totals</span> <span class="o">=</span> <span class="p">{}</span>

  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="c1"># In case of distribution strategy we can potentially run multiple steps</span>
    <span class="c1"># at the same time, we should account for that in the `seen` calculation.</span>
    <span class="n">num_steps</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;num_steps&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">+=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_steps</span>

    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">+=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span> <span class="o">*</span> <span class="n">batch_size</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">logs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;metrics&#39;</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">:</span>
          <span class="c1"># Make value available to next callbacks.</span>
          <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">:</span>
            <span class="n">logs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="n">logs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">totals</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">seen</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.TerminateOnNaN&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">TerminateOnNaN</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback that terminates training when a NaN loss is encountered.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">TerminateOnNaN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="k">def</span> <span class="nf">on_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">loss</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">loss</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Batch </span><span class="si">%d</span><span class="s1">: Invalid loss, terminating training&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">batch</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">True</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.ProgbarLogger&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ProgbarLogger</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback that prints metrics to stdout.</span>

<span class="sd">  Args:</span>
<span class="sd">      count_mode: One of `&quot;steps&quot;` or `&quot;samples&quot;`.</span>
<span class="sd">          Whether the progress bar should</span>
<span class="sd">          count samples seen or steps (batches) seen.</span>
<span class="sd">      stateful_metrics: Iterable of string names of metrics that</span>
<span class="sd">          should *not* be averaged over an epoch.</span>
<span class="sd">          Metrics in this list will be logged as-is.</span>
<span class="sd">          All others will be averaged over time (e.g. loss, etc).</span>
<span class="sd">          If not provided, defaults to the `Model`&#39;s metrics.</span>

<span class="sd">  Raises:</span>
<span class="sd">      ValueError: In case of invalid `count_mode`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">count_mode</span><span class="o">=</span><span class="s1">&#39;samples&#39;</span><span class="p">,</span> <span class="n">stateful_metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ProgbarLogger</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="n">count_mode</span> <span class="o">==</span> <span class="s1">&#39;samples&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">elif</span> <span class="n">count_mode</span> <span class="o">==</span> <span class="s1">&#39;steps&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unknown `count_mode`: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">count_mode</span><span class="p">))</span>
    <span class="c1"># Defaults to all Model&#39;s metrics except for loss.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">stateful_metrics</span><span class="p">)</span> <span class="k">if</span> <span class="n">stateful_metrics</span> <span class="k">else</span> <span class="nb">set</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_train_step</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_step</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_step</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hooks</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_called_in_fit</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;verbose&#39;</span><span class="p">]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="ow">and</span> <span class="s1">&#39;steps&#39;</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;steps&#39;</span><span class="p">]</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="ow">and</span> <span class="s1">&#39;samples&#39;</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;samples&#39;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Will be inferred at the end of the first epoch.</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hooks</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">try</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_train_counter</span>  <span class="c1"># pylint: disable=protected-access</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_test_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_test_counter</span>  <span class="c1"># pylint: disable=protected-access</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_predict_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_predict_counter</span>  <span class="c1"># pylint: disable=protected-access</span>
      <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hooks</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># When this logger is called inside `fit`, validation is silent.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_called_in_fit</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="k">def</span> <span class="nf">on_test_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_called_in_fit</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_reset_progbar</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_init_progbar</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_predict_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reset_progbar</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_init_progbar</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reset_progbar</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_init_progbar</span><span class="p">()</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">%d</span><span class="s1">/</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_batch_update_progbar</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_called_in_fit</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_batch_update_progbar</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_predict_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># Don&#39;t pass prediction results.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_batch_update_progbar</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_finalize_progbar</span><span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_step</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_called_in_fit</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_finalize_progbar</span><span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_step</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_predict_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_finalize_progbar</span><span class="p">(</span><span class="n">logs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_predict_step</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_reset_progbar</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="k">def</span> <span class="nf">_maybe_init_progbar</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Instantiate a `Progbar` if not yet, and update the stateful metrics.&quot;&quot;&quot;</span>
    <span class="c1"># TODO(rchao): Legacy TF1 code path may use list for</span>
    <span class="c1"># `self.stateful_metrics`. Remove &quot;cast to set&quot; when TF1 support is dropped.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">:</span>
      <span class="c1"># Update the existing stateful metrics as `self.model.metrics` may contain</span>
      <span class="c1"># updated metrics after `MetricsContainer` is built in the first train</span>
      <span class="c1"># step.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="o">.</span><span class="n">union</span><span class="p">(</span>
          <span class="nb">set</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">metrics</span><span class="p">))</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span> <span class="o">=</span> <span class="n">Progbar</span><span class="p">(</span>
          <span class="n">target</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span>
          <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
          <span class="n">stateful_metrics</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">,</span>
          <span class="n">unit_name</span><span class="o">=</span><span class="s1">&#39;step&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span> <span class="k">else</span> <span class="s1">&#39;sample&#39;</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span><span class="o">.</span><span class="n">_update_stateful_metrics</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stateful_metrics</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>

  <span class="k">def</span> <span class="nf">_implements_train_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hooks</span>

  <span class="k">def</span> <span class="nf">_implements_test_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hooks</span>

  <span class="k">def</span> <span class="nf">_implements_predict_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_call_batch_hooks</span>

  <span class="k">def</span> <span class="nf">_batch_update_progbar</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Updates the progbar.&quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_init_progbar</span><span class="p">()</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">=</span> <span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># One-indexed.</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># v1 path only.</span>
      <span class="n">logs</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
      <span class="n">batch_size</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
      <span class="n">num_steps</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;num_steps&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">logs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;batch&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
      <span class="n">add_seen</span> <span class="o">=</span> <span class="n">num_steps</span> <span class="o">*</span> <span class="n">batch_size</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">seen</span> <span class="o">+=</span> <span class="n">add_seen</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="c1"># Only block async when verbose = 1.</span>
      <span class="n">logs</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seen</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">finalize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_finalize_progbar</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="p">,</span> <span class="n">counter</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">logs</span> <span class="ow">or</span> <span class="p">{})</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">counter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">counter</span> <span class="o">=</span> <span class="n">counter</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_steps</span><span class="p">:</span>
          <span class="n">counter</span> <span class="o">*=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;size&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">counter</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">seen</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">progbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">()),</span> <span class="n">finalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.History&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">History</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback that records events into a `History` object.</span>

<span class="sd">  This callback is automatically applied to</span>
<span class="sd">  every Keras model. The `History` object</span>
<span class="sd">  gets returned by the `fit` method of models.</span>

<span class="sd">  Example:</span>

<span class="sd">  &gt;&gt;&gt; model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])</span>
<span class="sd">  &gt;&gt;&gt; model.compile(tf.keras.optimizers.SGD(), loss=&#39;mse&#39;)</span>
<span class="sd">  &gt;&gt;&gt; history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),</span>
<span class="sd">  ...                     epochs=10)</span>
<span class="sd">  &gt;&gt;&gt; print(history.params)</span>
<span class="sd">  {&#39;verbose&#39;: 1, &#39;epochs&#39;: 10, &#39;steps&#39;: 1}</span>
<span class="sd">  &gt;&gt;&gt; # check the keys of history object</span>
<span class="sd">  &gt;&gt;&gt; print(history.history.keys())</span>
<span class="sd">  dict_keys([&#39;loss&#39;])</span>

<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">History</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="p">{}</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epoch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">history</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="p">[])</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>

    <span class="c1"># Set the history attribute on the model after the epoch ends. This will</span>
    <span class="c1"># make sure that the state which is set is the latest one.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">history</span> <span class="o">=</span> <span class="bp">self</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.ModelCheckpoint&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ModelCheckpoint</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback to save the Keras model or model weights at some frequency.</span>

<span class="sd">  `ModelCheckpoint` callback is used in conjunction with training using</span>
<span class="sd">  `model.fit()` to save a model or weights (in a checkpoint file) at some</span>
<span class="sd">  interval, so the model or weights can be loaded later to continue the training</span>
<span class="sd">  from the state saved.</span>

<span class="sd">  A few options this callback provides include:</span>

<span class="sd">  - Whether to only keep the model that has achieved the &quot;best performance&quot; so</span>
<span class="sd">    far, or whether to save the model at the end of every epoch regardless of</span>
<span class="sd">    performance.</span>
<span class="sd">  - Definition of &#39;best&#39;; which quantity to monitor and whether it should be</span>
<span class="sd">    maximized or minimized.</span>
<span class="sd">  - The frequency it should save at. Currently, the callback supports saving at</span>
<span class="sd">    the end of every epoch, or after a fixed number of training batches.</span>
<span class="sd">  - Whether only weights are saved, or the whole model is saved.</span>

<span class="sd">  Note: If you get `WARNING:tensorflow:Can save best model only with &lt;name&gt;</span>
<span class="sd">  available, skipping` see the description of the `monitor` argument for</span>
<span class="sd">  details on how to get this right.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  model.compile(loss=..., optimizer=...,</span>
<span class="sd">                metrics=[&#39;accuracy&#39;])</span>

<span class="sd">  EPOCHS = 10</span>
<span class="sd">  checkpoint_filepath = &#39;/tmp/checkpoint&#39;</span>
<span class="sd">  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(</span>
<span class="sd">      filepath=checkpoint_filepath,</span>
<span class="sd">      save_weights_only=True,</span>
<span class="sd">      monitor=&#39;val_accuracy&#39;,</span>
<span class="sd">      mode=&#39;max&#39;,</span>
<span class="sd">      save_best_only=True)</span>

<span class="sd">  # Model weights are saved at the end of every epoch, if it&#39;s the best seen</span>
<span class="sd">  # so far.</span>
<span class="sd">  model.fit(epochs=EPOCHS, callbacks=[model_checkpoint_callback])</span>

<span class="sd">  # The model weights (that are considered the best) are loaded into the model.</span>
<span class="sd">  model.load_weights(checkpoint_filepath)</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">      filepath: string or `PathLike`, path to save the model file. e.g.</span>
<span class="sd">        filepath = os.path.join(working_dir, &#39;ckpt&#39;, file_name). `filepath`</span>
<span class="sd">        can contain named formatting options, which will be filled the value of</span>
<span class="sd">        `epoch` and keys in `logs` (passed in `on_epoch_end`). For example: if</span>
<span class="sd">        `filepath` is `weights.{epoch:02d}-{val_loss:.2f}.hdf5`, then the model</span>
<span class="sd">        checkpoints will be saved with the epoch number and the validation loss</span>
<span class="sd">        in the filename. The directory of the filepath should not be reused by</span>
<span class="sd">        any other callbacks to avoid conflicts.</span>
<span class="sd">      monitor: The metric name to monitor. Typically the metrics are set by the</span>
<span class="sd">        `Model.compile` method. Note:</span>

<span class="sd">        * Prefix the name with `&quot;val_`&quot; to monitor validation metrics.</span>
<span class="sd">        * Use `&quot;loss&quot;` or &quot;`val_loss`&quot; to monitor the model&#39;s total loss.</span>
<span class="sd">        * If you specify metrics as strings, like `&quot;accuracy&quot;`, pass the same</span>
<span class="sd">          string (with or without the `&quot;val_&quot;` prefix).</span>
<span class="sd">        * If you pass `metrics.Metric` objects, `monitor` should be set to</span>
<span class="sd">          `metric.name`</span>
<span class="sd">        * If you&#39;re not sure about the metric names you can check the contents</span>
<span class="sd">          of the `history.history` dictionary returned by</span>
<span class="sd">          `history = model.fit()`</span>
<span class="sd">        * Multi-output models set additional prefixes on the metric names.</span>

<span class="sd">      verbose: verbosity mode, 0 or 1.</span>
<span class="sd">      save_best_only: if `save_best_only=True`, it only saves when the model</span>
<span class="sd">        is considered the &quot;best&quot; and the latest best model according to the</span>
<span class="sd">        quantity monitored will not be overwritten. If `filepath` doesn&#39;t</span>
<span class="sd">        contain formatting options like `{epoch}` then `filepath` will be</span>
<span class="sd">        overwritten by each new better model.</span>
<span class="sd">      mode: one of {&#39;auto&#39;, &#39;min&#39;, &#39;max&#39;}. If `save_best_only=True`, the</span>
<span class="sd">        decision to overwrite the current save file is made based on either</span>
<span class="sd">        the maximization or the minimization of the monitored quantity.</span>
<span class="sd">        For `val_acc`, this should be `max`, for `val_loss` this should be</span>
<span class="sd">        `min`, etc. In `auto` mode, the mode is set to `max` if the quantities</span>
<span class="sd">        monitored are &#39;acc&#39; or start with &#39;fmeasure&#39; and are set to `min` for</span>
<span class="sd">        the rest of the quantities.</span>
<span class="sd">      save_weights_only: if True, then only the model&#39;s weights will be saved</span>
<span class="sd">        (`model.save_weights(filepath)`), else the full model is saved</span>
<span class="sd">        (`model.save(filepath)`).</span>
<span class="sd">      save_freq: `&#39;epoch&#39;` or integer. When using `&#39;epoch&#39;`, the callback saves</span>
<span class="sd">        the model after each epoch. When using integer, the callback saves the</span>
<span class="sd">        model at end of this many batches. If the `Model` is compiled with</span>
<span class="sd">        `steps_per_execution=N`, then the saving criteria will be</span>
<span class="sd">        checked every Nth batch. Note that if the saving isn&#39;t aligned to</span>
<span class="sd">        epochs, the monitored metric may potentially be less reliable (it</span>
<span class="sd">        could reflect as little as 1 batch, since the metrics get reset every</span>
<span class="sd">        epoch). Defaults to `&#39;epoch&#39;`.</span>
<span class="sd">      options: Optional `tf.train.CheckpointOptions` object if</span>
<span class="sd">        `save_weights_only` is true or optional `tf.saved_model.SaveOptions`</span>
<span class="sd">        object if `save_weights_only` is false.</span>
<span class="sd">      **kwargs: Additional arguments for backwards compatibility. Possible key</span>
<span class="sd">        is `period`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">filepath</span><span class="p">,</span>
               <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
               <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">save_best_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">save_weights_only</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
               <span class="n">save_freq</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span>
               <span class="n">options</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="o">=</span> <span class="n">monitor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span> <span class="o">=</span> <span class="n">path_to_string</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_best_only</span> <span class="o">=</span> <span class="n">save_best_only</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span> <span class="o">=</span> <span class="n">save_weights_only</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">=</span> <span class="n">save_freq</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_batches_seen_since_last_saving</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch_seen</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="n">save_weights_only</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">options</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span>
          <span class="n">options</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointOptions</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_options</span> <span class="o">=</span> <span class="n">options</span> <span class="ow">or</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointOptions</span><span class="p">()</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;If save_weights_only is True, then `options` must be &#39;</span>
                        <span class="s1">&#39;either None or a tf.train.CheckpointOptions&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">options</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">options</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">SaveOptions</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_options</span> <span class="o">=</span> <span class="n">options</span> <span class="ow">or</span> <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">SaveOptions</span><span class="p">()</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;If save_weights_only is False, then `options` must be&#39;</span>
                        <span class="s1">&#39;either None or a tf.saved_model.SaveOptions&#39;</span><span class="p">)</span>

    <span class="c1"># Deprecated field `load_weights_on_restart` is for loading the checkpoint</span>
    <span class="c1"># file from `filepath` at the start of `model.fit()`</span>
    <span class="c1"># TODO(rchao): Remove the arg during next breaking release.</span>
    <span class="k">if</span> <span class="s1">&#39;load_weights_on_restart&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_on_restart</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;load_weights_on_restart&#39;</span><span class="p">]</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`load_weights_on_restart` argument is deprecated. &#39;</span>
                      <span class="s1">&#39;Please use `model.load_weights()` for loading weights &#39;</span>
                      <span class="s1">&#39;before the start of `model.fit()`.&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_on_restart</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Deprecated field `period` is for the number of epochs between which</span>
    <span class="c1"># the model is saved.</span>
    <span class="k">if</span> <span class="s1">&#39;period&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;period&#39;</span><span class="p">]</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`period` argument is deprecated. Please use `save_freq` &#39;</span>
                      <span class="s1">&#39;to specify the frequency in number of batches seen.&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">period</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">]:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;ModelCheckpoint mode </span><span class="si">%s</span><span class="s1"> is unknown, &#39;</span>
                      <span class="s1">&#39;fallback to auto mode.&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
      <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="s1">&#39;acc&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;fmeasure&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">!=</span> <span class="s1">&#39;epoch&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unrecognized save_freq: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">))</span>

    <span class="c1"># Only the chief worker writes model checkpoints, but all workers</span>
    <span class="c1"># restore checkpoint at on_train_begin().</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_chief_worker_only</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_weights_on_restart</span><span class="p">:</span>
      <span class="n">filepath_to_load</span> <span class="o">=</span> <span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_get_most_recently_modified_file_matching_pattern</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="p">))</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">filepath_to_load</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint_exists</span><span class="p">(</span><span class="n">filepath_to_load</span><span class="p">)):</span>
        <span class="k">try</span><span class="p">:</span>
          <span class="c1"># `filepath` may contain placeholders such as `{epoch:02d}`, and</span>
          <span class="c1"># thus it attempts to load the most recently modified file with file</span>
          <span class="c1"># name matching the pattern.</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">filepath_to_load</span><span class="p">)</span>
        <span class="k">except</span> <span class="p">(</span><span class="ne">IOError</span><span class="p">,</span> <span class="ne">ValueError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
          <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Error loading file from </span><span class="si">{}</span><span class="s1">. Reason: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
              <span class="n">filepath_to_load</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">_implements_train_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Only call batch hooks when saving on batch</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">!=</span> <span class="s1">&#39;epoch&#39;</span>

  <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_save_on_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_save_model</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_current_epoch</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_current_epoch</span> <span class="o">=</span> <span class="n">epoch</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="c1"># pylint: disable=protected-access</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">==</span> <span class="s1">&#39;epoch&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_save_model</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="n">logs</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_should_save_on_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Handles batch-level saving logic, supports steps_per_execution.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span> <span class="o">==</span> <span class="s1">&#39;epoch&#39;</span><span class="p">:</span>
      <span class="k">return</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">batch</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch_seen</span><span class="p">:</span>  <span class="c1"># New epoch.</span>
      <span class="n">add_batches</span> <span class="o">=</span> <span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># batches are zero-indexed.</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">add_batches</span> <span class="o">=</span> <span class="n">batch</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch_seen</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_batches_seen_since_last_saving</span> <span class="o">+=</span> <span class="n">add_batches</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_last_batch_seen</span> <span class="o">=</span> <span class="n">batch</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batches_seen_since_last_saving</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_batches_seen_since_last_saving</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">return</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="kc">False</span>

  <span class="k">def</span> <span class="nf">_save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Saves the model.</span>

<span class="sd">    Args:</span>
<span class="sd">        epoch: the epoch this iteration is in.</span>
<span class="sd">        batch: the batch this iteration is in. `None` if the `save_freq`</span>
<span class="sd">          is set to `epoch`.</span>
<span class="sd">        logs: the `logs` dict passed in to `on_batch_end` or `on_epoch_end`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_freq</span><span class="p">,</span>
                  <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">period</span><span class="p">:</span>
      <span class="c1"># Block only when saving interval is reached.</span>
      <span class="n">logs</span> <span class="o">=</span> <span class="n">tf_utils</span><span class="o">.</span><span class="n">sync_to_numpy_or_python_type</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">epochs_since_last_save</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="n">filepath</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_file_path</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

      <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_best_only</span><span class="p">:</span>
          <span class="n">current</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)</span>
          <span class="k">if</span> <span class="n">current</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Can save best model only with </span><span class="si">%s</span><span class="s1"> available, &#39;</span>
                            <span class="s1">&#39;skipping.&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">):</span>
              <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch </span><span class="si">%05d</span><span class="s1">: </span><span class="si">%s</span><span class="s1"> improved from </span><span class="si">%0.5f</span><span class="s1"> to </span><span class="si">%0.5f</span><span class="s1">,&#39;</span>
                      <span class="s1">&#39; saving model to </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">,</span> <span class="n">current</span><span class="p">,</span> <span class="n">filepath</span><span class="p">))</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">current</span>
              <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span>
                    <span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="p">)</span>
              <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
              <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch </span><span class="si">%05d</span><span class="s1">: </span><span class="si">%s</span><span class="s1"> did not improve from </span><span class="si">%0.5f</span><span class="s1">&#39;</span> <span class="o">%</span>
                      <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch </span><span class="si">%05d</span><span class="s1">: saving model to </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">filepath</span><span class="p">))</span>
          <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_weights_only</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span>
                <span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="p">)</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_options</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_remove_file</span><span class="p">()</span>
      <span class="k">except</span> <span class="ne">IsADirectoryError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>  <span class="c1"># h5py 3.x</span>
        <span class="k">raise</span> <span class="ne">IOError</span><span class="p">(</span><span class="s1">&#39;Please specify a non-directory filepath for &#39;</span>
                      <span class="s1">&#39;ModelCheckpoint. Filepath used is an existing &#39;</span>
                      <span class="s1">&#39;directory: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">filepath</span><span class="p">))</span>
      <span class="k">except</span> <span class="ne">IOError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>  <span class="c1"># h5py 2.x</span>
        <span class="c1"># `e.errno` appears to be `None` so checking the content of `e.args[0]`.</span>
        <span class="k">if</span> <span class="s1">&#39;is a directory&#39;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
          <span class="k">raise</span> <span class="ne">IOError</span><span class="p">(</span><span class="s1">&#39;Please specify a non-directory filepath for &#39;</span>
                        <span class="s1">&#39;ModelCheckpoint. Filepath used is an existing &#39;</span>
                        <span class="s1">&#39;directory: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">filepath</span><span class="p">))</span>
        <span class="c1"># Re-throw the error for any other causes.</span>
        <span class="k">raise</span> <span class="n">e</span>

  <span class="k">def</span> <span class="nf">_get_file_path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the file path for checkpoint.&quot;&quot;&quot;</span>
    <span class="c1"># pylint: disable=protected-access</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="c1"># `filepath` may contain placeholders such as `{epoch:02d}`,`{batch:02d}`</span>
      <span class="c1"># and `{mape:.2f}`. A mismatch between logged metrics and the path&#39;s</span>
      <span class="c1"># placeholders can cause formatting to fail.</span>
      <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="s1">&#39;batch&#39;</span> <span class="ow">in</span> <span class="n">logs</span><span class="p">:</span>
        <span class="n">file_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">logs</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">file_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">logs</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">KeyError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">KeyError</span><span class="p">(</span><span class="s1">&#39;Failed to format this callback filepath: &quot;</span><span class="si">{}</span><span class="s1">&quot;. &#39;</span>
                     <span class="s1">&#39;Reason: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filepath</span><span class="p">,</span> <span class="n">e</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_write_filepath</span> <span class="o">=</span> <span class="n">distributed_file_utils</span><span class="o">.</span><span class="n">write_filepath</span><span class="p">(</span>
        <span class="n">file_path</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_write_filepath</span>

  <span class="k">def</span> <span class="nf">_maybe_remove_file</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Remove the checkpoint directory in multi-worker training where this worker</span>
    <span class="c1"># should not checkpoint. It is a dummy directory previously saved for sync</span>
    <span class="c1"># distributed training.</span>
    <span class="n">distributed_file_utils</span><span class="o">.</span><span class="n">remove_temp_dir_with_filepath</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_write_filepath</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_checkpoint_exists</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns whether the checkpoint `filepath` refers to exists.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">filepath</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s1">&#39;.h5&#39;</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
    <span class="n">tf_saved_model_exists</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
    <span class="n">tf_weights_only_checkpoint_exists</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span>
        <span class="n">filepath</span> <span class="o">+</span> <span class="s1">&#39;.index&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf_saved_model_exists</span> <span class="ow">or</span> <span class="n">tf_weights_only_checkpoint_exists</span>

  <span class="k">def</span> <span class="nf">_get_most_recently_modified_file_matching_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pattern</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the most recently modified filepath matching pattern.</span>

<span class="sd">    Pattern may contain python formatting placeholder. If</span>
<span class="sd">    `tf.train.latest_checkpoint()` does not return None, use that; otherwise,</span>
<span class="sd">    check for most recently modified one that matches the pattern.</span>

<span class="sd">    In the rare case where there are more than one pattern-matching file having</span>
<span class="sd">    the same modified time that is most recent among all, return the filepath</span>
<span class="sd">    that is largest (by `&gt;` operator, lexicographically using the numeric</span>
<span class="sd">    equivalents). This provides a tie-breaker when multiple files are most</span>
<span class="sd">    recent. Note that a larger `filepath` can sometimes indicate a later time of</span>
<span class="sd">    modification (for instance, when epoch/batch is used as formatting option),</span>
<span class="sd">    but not necessarily (when accuracy or loss is used). The tie-breaker is</span>
<span class="sd">    put in the logic as best effort to return the most recent, and to avoid</span>
<span class="sd">    undeterministic result.</span>

<span class="sd">    Modified time of a file is obtained with `os.path.getmtime()`.</span>

<span class="sd">    This utility function is best demonstrated via an example:</span>

<span class="sd">    ```python</span>
<span class="sd">    file_pattern = &#39;f.batch{batch:02d}epoch{epoch:02d}.h5&#39;</span>
<span class="sd">    test_dir = self.get_temp_dir()</span>
<span class="sd">    path_pattern = os.path.join(test_dir, file_pattern)</span>
<span class="sd">    file_paths = [</span>
<span class="sd">        os.path.join(test_dir, file_name) for file_name in</span>
<span class="sd">        [&#39;f.batch03epoch02.h5&#39;, &#39;f.batch02epoch02.h5&#39;, &#39;f.batch01epoch01.h5&#39;]</span>
<span class="sd">    ]</span>
<span class="sd">    for file_path in file_paths:</span>
<span class="sd">      # Write something to each of the files</span>
<span class="sd">    self.assertEqual(</span>
<span class="sd">        _get_most_recently_modified_file_matching_pattern(path_pattern),</span>
<span class="sd">        file_paths[-1])</span>
<span class="sd">    ```</span>

<span class="sd">    Args:</span>
<span class="sd">        pattern: The file pattern that may optionally contain python placeholder</span>
<span class="sd">            such as `{epoch:02d}`.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The most recently modified file&#39;s full filepath matching `pattern`. If</span>
<span class="sd">        `pattern` does not contain any placeholder, this returns the filepath</span>
<span class="sd">        that</span>
<span class="sd">        exactly matches `pattern`. Returns `None` if no match is found.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dir_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
    <span class="n">base_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">pattern</span><span class="p">)</span>
    <span class="n">base_name_regex</span> <span class="o">=</span> <span class="s1">&#39;^&#39;</span> <span class="o">+</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;{.*}&#39;</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;.*&#39;</span><span class="p">,</span> <span class="n">base_name</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;$&#39;</span>

    <span class="c1"># If tf.train.latest_checkpoint tells us there exists a latest checkpoint,</span>
    <span class="c1"># use that as it is more robust than `os.path.getmtime()`.</span>
    <span class="n">latest_tf_checkpoint</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="n">dir_name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">latest_tf_checkpoint</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span>
        <span class="n">base_name_regex</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">latest_tf_checkpoint</span><span class="p">)):</span>
      <span class="k">return</span> <span class="n">latest_tf_checkpoint</span>

    <span class="n">latest_mod_time</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">file_path_with_latest_mod_time</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">n_file_with_latest_mod_time</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">file_path_with_largest_file_name</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">dir_name</span><span class="p">):</span>
        <span class="c1"># Only consider if `file_name` matches the pattern.</span>
        <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">base_name_regex</span><span class="p">,</span> <span class="n">file_name</span><span class="p">):</span>
          <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_name</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
          <span class="n">mod_time</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">getmtime</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
          <span class="k">if</span> <span class="p">(</span><span class="n">file_path_with_largest_file_name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span>
              <span class="n">file_path</span> <span class="o">&gt;</span> <span class="n">file_path_with_largest_file_name</span><span class="p">):</span>
            <span class="n">file_path_with_largest_file_name</span> <span class="o">=</span> <span class="n">file_path</span>
          <span class="k">if</span> <span class="n">mod_time</span> <span class="o">&gt;</span> <span class="n">latest_mod_time</span><span class="p">:</span>
            <span class="n">latest_mod_time</span> <span class="o">=</span> <span class="n">mod_time</span>
            <span class="n">file_path_with_latest_mod_time</span> <span class="o">=</span> <span class="n">file_path</span>
            <span class="c1"># In the case a file with later modified time is found, reset</span>
            <span class="c1"># the counter for the number of files with latest modified time.</span>
            <span class="n">n_file_with_latest_mod_time</span> <span class="o">=</span> <span class="mi">1</span>
          <span class="k">elif</span> <span class="n">mod_time</span> <span class="o">==</span> <span class="n">latest_mod_time</span><span class="p">:</span>
            <span class="c1"># In the case a file has modified time tied with the most recent,</span>
            <span class="c1"># increment the counter for the number of files with latest modified</span>
            <span class="c1"># time by 1.</span>
            <span class="n">n_file_with_latest_mod_time</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">if</span> <span class="n">n_file_with_latest_mod_time</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
      <span class="c1"># Return the sole file that has most recent modified time.</span>
      <span class="k">return</span> <span class="n">file_path_with_latest_mod_time</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># If there are more than one file having latest modified time, return</span>
      <span class="c1"># the file path with the largest file name.</span>
      <span class="k">return</span> <span class="n">file_path_with_largest_file_name</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.experimental.BackupAndRestore&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[])</span>
<span class="k">class</span> <span class="nc">BackupAndRestore</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback to back up and restore the training state.</span>

<span class="sd">  `BackupAndRestore` callback is intended to recover from interruptions that</span>
<span class="sd">  happened in the middle of a model.fit execution by backing up the</span>
<span class="sd">  training states in a temporary checkpoint file (based on TF CheckpointManager)</span>
<span class="sd">  at the end of each epoch. If training restarted before completion, the</span>
<span class="sd">  training state and model are restored to the most recently saved state at the</span>
<span class="sd">  beginning of a new model.fit() run.</span>
<span class="sd">  Note that user is responsible to bring jobs back up.</span>
<span class="sd">  This callback is important for the backup and restore mechanism for fault</span>
<span class="sd">  tolerance purpose. And the model to be restored from an previous checkpoint is</span>
<span class="sd">  expected to be the same as the one used to back up. If user changes arguments</span>
<span class="sd">  passed to compile or fit, the checkpoint saved for fault tolerance can become</span>
<span class="sd">  invalid.</span>

<span class="sd">  Note:</span>
<span class="sd">  1. This callback is not compatible with disabling eager execution.</span>
<span class="sd">  2. A checkpoint is saved at the end of each epoch, when restoring we&#39;ll redo</span>
<span class="sd">  any partial work from an unfinished epoch in which the training got restarted</span>
<span class="sd">  (so the work done before a interruption doesn&#39;t affect the final model state).</span>
<span class="sd">  3. This works for both single worker and multi-worker mode, only</span>
<span class="sd">  MirroredStrategy and MultiWorkerMirroredStrategy are supported for now.</span>

<span class="sd">  Example:</span>

<span class="sd">  &gt;&gt;&gt; class InterruptingCallback(tf.keras.callbacks.Callback):</span>
<span class="sd">  ...   def on_epoch_begin(self, epoch, logs=None):</span>
<span class="sd">  ...     if epoch == 4:</span>
<span class="sd">  ...       raise RuntimeError(&#39;Interrupting!&#39;)</span>
<span class="sd">  &gt;&gt;&gt; callback = tf.keras.callbacks.experimental.BackupAndRestore(</span>
<span class="sd">  ... backup_dir=&quot;/tmp/backup&quot;)</span>
<span class="sd">  &gt;&gt;&gt; model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])</span>
<span class="sd">  &gt;&gt;&gt; model.compile(tf.keras.optimizers.SGD(), loss=&#39;mse&#39;)</span>
<span class="sd">  &gt;&gt;&gt; try:</span>
<span class="sd">  ...   model.fit(np.arange(100).reshape(5, 20), np.zeros(5), epochs=10,</span>
<span class="sd">  ...             batch_size=1, callbacks=[callback, InterruptingCallback()],</span>
<span class="sd">  ...             verbose=0)</span>
<span class="sd">  ... except:</span>
<span class="sd">  ...   pass</span>
<span class="sd">  &gt;&gt;&gt; history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5), epochs=10,</span>
<span class="sd">  ...             batch_size=1, callbacks=[callback], verbose=0)</span>
<span class="sd">  &gt;&gt;&gt; # Only 6 more epochs are run, since first trainning got interrupted at</span>
<span class="sd">  &gt;&gt;&gt; # zero-indexed epoch 4, second training will continue from 4 to 9.</span>
<span class="sd">  &gt;&gt;&gt; len(history.history[&#39;loss&#39;])</span>
<span class="sd">  6</span>

<span class="sd">  Args:</span>
<span class="sd">      backup_dir: String, path to store the checkpoint.</span>
<span class="sd">        e.g. backup_dir = os.path.join(working_dir, &#39;backup&#39;)</span>
<span class="sd">        This is the directory in which the system stores temporary files to</span>
<span class="sd">        recover the model from jobs terminated unexpectedly. The directory</span>
<span class="sd">        cannot be reused elsewhere to store other files, e.g. by</span>
<span class="sd">        BackupAndRestore callback of another training, or by another callback</span>
<span class="sd">        (ModelCheckpoint) of the same training.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">backup_dir</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BackupAndRestore</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">backup_dir</span> <span class="o">=</span> <span class="n">backup_dir</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_supported_strategies</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MirroredStrategy</span><span class="p">,</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MultiWorkerMirroredStrategy</span><span class="p">,</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">TPUStrategy</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">TPUStrategy</span><span class="p">,</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">ParameterServerStrategy</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">executing_eagerly</span><span class="p">():</span>
      <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">inside_function</span><span class="p">():</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;This Callback</span><span class="se">\&#39;</span><span class="s1">s method contains Python state and &#39;</span>
                         <span class="s1">&#39;should be called outside of `tf.function`s.&#39;</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>  <span class="c1"># Legacy graph mode:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s1">&#39;BackupAndRestore only supports eager mode. In graph &#39;</span>
            <span class="s1">&#39;mode, consider using ModelCheckpoint to manually save &#39;</span>
            <span class="s1">&#39;and restore weights with `model.load_weights()` and by &#39;</span>
            <span class="s1">&#39;providing `initial_epoch` in `model.fit()` for fault tolerance.&#39;</span><span class="p">)</span>

    <span class="c1"># Only the chief worker writes model checkpoints, but all workers</span>
    <span class="c1"># restore checkpoint at on_train_begin().</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_chief_worker_only</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># TrainingState is used to manage the training state needed for</span>
    <span class="c1"># failure-recovery of a worker in training.</span>
    <span class="c1"># pylint: disable=protected-access</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_distribution_strategy</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_supported_strategies</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
          <span class="s1">&#39;</span><span class="si">%s</span><span class="s1"> is not supported yet. &#39;</span>
          <span class="s1">&#39;Currently BackupAndRestore callback only supports empty strategy, &#39;</span>
          <span class="s1">&#39;MirroredStrategy, MultiWorkerMirroredStrategy and TPUStrategy.&#39;</span> <span class="o">%</span>
          <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_training_state</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">worker_training_state</span><span class="o">.</span><span class="n">WorkerTrainingState</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">backup_dir</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_training_state</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span><span class="o">.</span><span class="n">restore</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># pylint: disable=protected-access</span>
    <span class="c1"># On exit of training, delete the training state backup file that was saved</span>
    <span class="c1"># for the purpose of worker recovery.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span><span class="o">.</span><span class="n">delete_backup</span><span class="p">()</span>

    <span class="c1"># Clean up the training state.</span>
    <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span>
    <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_training_state</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># Back up the model and current epoch for possible future recovery.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_training_state</span><span class="o">.</span><span class="n">back_up</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.EarlyStopping&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">EarlyStopping</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Stop training when a monitored metric has stopped improving.</span>

<span class="sd">  Assuming the goal of a training is to minimize the loss. With this, the</span>
<span class="sd">  metric to be monitored would be `&#39;loss&#39;`, and mode would be `&#39;min&#39;`. A</span>
<span class="sd">  `model.fit()` training loop will check at end of every epoch whether</span>
<span class="sd">  the loss is no longer decreasing, considering the `min_delta` and</span>
<span class="sd">  `patience` if applicable. Once it&#39;s found no longer decreasing,</span>
<span class="sd">  `model.stop_training` is marked True and the training terminates.</span>

<span class="sd">  The quantity to be monitored needs to be available in `logs` dict.</span>
<span class="sd">  To make it so, pass the loss or metrics at `model.compile()`.</span>

<span class="sd">  Args:</span>
<span class="sd">    monitor: Quantity to be monitored.</span>
<span class="sd">    min_delta: Minimum change in the monitored quantity</span>
<span class="sd">        to qualify as an improvement, i.e. an absolute</span>
<span class="sd">        change of less than min_delta, will count as no</span>
<span class="sd">        improvement.</span>
<span class="sd">    patience: Number of epochs with no improvement</span>
<span class="sd">        after which training will be stopped.</span>
<span class="sd">    verbose: verbosity mode.</span>
<span class="sd">    mode: One of `{&quot;auto&quot;, &quot;min&quot;, &quot;max&quot;}`. In `min` mode,</span>
<span class="sd">        training will stop when the quantity</span>
<span class="sd">        monitored has stopped decreasing; in `&quot;max&quot;`</span>
<span class="sd">        mode it will stop when the quantity</span>
<span class="sd">        monitored has stopped increasing; in `&quot;auto&quot;`</span>
<span class="sd">        mode, the direction is automatically inferred</span>
<span class="sd">        from the name of the monitored quantity.</span>
<span class="sd">    baseline: Baseline value for the monitored quantity.</span>
<span class="sd">        Training will stop if the model doesn&#39;t show improvement over the</span>
<span class="sd">        baseline.</span>
<span class="sd">    restore_best_weights: Whether to restore model weights from</span>
<span class="sd">        the epoch with the best value of the monitored quantity.</span>
<span class="sd">        If False, the model weights obtained at the last step of</span>
<span class="sd">        training are used. An epoch will be restored regardless</span>
<span class="sd">        of the performance relative to the `baseline`. If no epoch</span>
<span class="sd">        improves on `baseline`, training will run for `patience`</span>
<span class="sd">        epochs and restore weights from the best epoch in that set.</span>

<span class="sd">  Example:</span>

<span class="sd">  &gt;&gt;&gt; callback = tf.keras.callbacks.EarlyStopping(monitor=&#39;loss&#39;, patience=3)</span>
<span class="sd">  &gt;&gt;&gt; # This callback will stop the training when there is no improvement in</span>
<span class="sd">  &gt;&gt;&gt; # the loss for three consecutive epochs.</span>
<span class="sd">  &gt;&gt;&gt; model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])</span>
<span class="sd">  &gt;&gt;&gt; model.compile(tf.keras.optimizers.SGD(), loss=&#39;mse&#39;)</span>
<span class="sd">  &gt;&gt;&gt; history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),</span>
<span class="sd">  ...                     epochs=10, batch_size=1, callbacks=[callback],</span>
<span class="sd">  ...                     verbose=0)</span>
<span class="sd">  &gt;&gt;&gt; len(history.history[&#39;loss&#39;])  # Only 4 epochs are run.</span>
<span class="sd">  4</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
               <span class="n">min_delta</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">patience</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
               <span class="n">baseline</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">restore_best_weights</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">EarlyStopping</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="o">=</span> <span class="n">monitor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span> <span class="o">=</span> <span class="n">baseline</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">min_delta</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span> <span class="o">=</span> <span class="n">restore_best_weights</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">]:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;EarlyStopping mode </span><span class="si">%s</span><span class="s1"> is unknown, &#39;</span>
                      <span class="s1">&#39;fallback to auto mode.&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
      <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span>

    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>
    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="s1">&#39;acc&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">*=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># Allow instances to be re-used</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span> <span class="k">else</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">current</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_monitor_value</span><span class="p">(</span><span class="n">logs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">current</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">return</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="c1"># Restore the weights after first epoch if no progress is ever made.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_improvement</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">current</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span>
      <span class="c1"># Only restart wait if we beat both the baseline and our previous best.</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_improvement</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">baseline</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">=</span> <span class="n">epoch</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">restore_best_weights</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
          <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Restoring model weights from the end of the best epoch.&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">best_weights</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">%05d</span><span class="s1">: early stopping&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stopped_epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">get_monitor_value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">monitor_value</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">monitor_value</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Early stopping conditioned on metric `</span><span class="si">%s</span><span class="s1">` &#39;</span>
                      <span class="s1">&#39;which is not available. Available metrics are: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>
    <span class="k">return</span> <span class="n">monitor_value</span>

  <span class="k">def</span> <span class="nf">_is_improvement</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">monitor_value</span><span class="p">,</span> <span class="n">reference_value</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span><span class="p">(</span><span class="n">monitor_value</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span><span class="p">,</span> <span class="n">reference_value</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.RemoteMonitor&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">RemoteMonitor</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback used to stream events to a server.</span>

<span class="sd">  Requires the `requests` library.</span>
<span class="sd">  Events are sent to `root + &#39;/publish/epoch/end/&#39;` by default. Calls are</span>
<span class="sd">  HTTP POST, with a `data` argument which is a</span>
<span class="sd">  JSON-encoded dictionary of event data.</span>
<span class="sd">  If `send_as_json=True`, the content type of the request will be</span>
<span class="sd">  `&quot;application/json&quot;`.</span>
<span class="sd">  Otherwise the serialized JSON will be sent within a form.</span>

<span class="sd">  Args:</span>
<span class="sd">    root: String; root url of the target server.</span>
<span class="sd">    path: String; path relative to `root` to which the events will be sent.</span>
<span class="sd">    field: String; JSON field under which the data will be stored.</span>
<span class="sd">        The field is used only if the payload is sent within a form</span>
<span class="sd">        (i.e. send_as_json is set to False).</span>
<span class="sd">    headers: Dictionary; optional custom HTTP headers.</span>
<span class="sd">    send_as_json: Boolean; whether the request should be</span>
<span class="sd">        sent as `&quot;application/json&quot;`.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">root</span><span class="o">=</span><span class="s1">&#39;http://localhost:9000&#39;</span><span class="p">,</span>
               <span class="n">path</span><span class="o">=</span><span class="s1">&#39;/publish/epoch/end/&#39;</span><span class="p">,</span>
               <span class="n">field</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span>
               <span class="n">headers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">send_as_json</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">RemoteMonitor</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">root</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">path</span> <span class="o">=</span> <span class="n">path</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">field</span> <span class="o">=</span> <span class="n">field</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">headers</span> <span class="o">=</span> <span class="n">headers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">send_as_json</span> <span class="o">=</span> <span class="n">send_as_json</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">requests</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s1">&#39;RemoteMonitor requires the `requests` library.&#39;</span><span class="p">)</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">send</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">send</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
      <span class="c1"># np.ndarray and np.generic are not scalar types</span>
      <span class="c1"># therefore we must unwrap their scalar values and</span>
      <span class="c1"># pass to the json-serializable dict &#39;send&#39;</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">generic</span><span class="p">)):</span>
        <span class="n">send</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">send</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">v</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">send_as_json</span><span class="p">:</span>
        <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">send</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="p">,</span> <span class="p">{</span><span class="bp">self</span><span class="o">.</span><span class="n">field</span><span class="p">:</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">send</span><span class="p">)},</span>
            <span class="n">headers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">headers</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">RequestException</span><span class="p">:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Warning: could not reach RemoteMonitor &#39;</span>
                      <span class="s1">&#39;root server at &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">))</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.LearningRateScheduler&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LearningRateScheduler</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Learning rate scheduler.</span>

<span class="sd">  At the beginning of every epoch, this callback gets the updated learning rate</span>
<span class="sd">  value from `schedule` function provided at `__init__`, with the current epoch</span>
<span class="sd">  and current learning rate, and applies the updated learning rate</span>
<span class="sd">  on the optimizer.</span>

<span class="sd">  Args:</span>
<span class="sd">    schedule: a function that takes an epoch index (integer, indexed from 0)</span>
<span class="sd">        and current learning rate (float) as inputs and returns a new</span>
<span class="sd">        learning rate as output (float).</span>
<span class="sd">    verbose: int. 0: quiet, 1: update messages.</span>

<span class="sd">  Example:</span>

<span class="sd">  &gt;&gt;&gt; # This function keeps the initial learning rate for the first ten epochs</span>
<span class="sd">  &gt;&gt;&gt; # and decreases it exponentially after that.</span>
<span class="sd">  &gt;&gt;&gt; def scheduler(epoch, lr):</span>
<span class="sd">  ...   if epoch &lt; 10:</span>
<span class="sd">  ...     return lr</span>
<span class="sd">  ...   else:</span>
<span class="sd">  ...     return lr * tf.math.exp(-0.1)</span>
<span class="sd">  &gt;&gt;&gt;</span>
<span class="sd">  &gt;&gt;&gt; model = tf.keras.models.Sequential([tf.keras.layers.Dense(10)])</span>
<span class="sd">  &gt;&gt;&gt; model.compile(tf.keras.optimizers.SGD(), loss=&#39;mse&#39;)</span>
<span class="sd">  &gt;&gt;&gt; round(model.optimizer.lr.numpy(), 5)</span>
<span class="sd">  0.01</span>

<span class="sd">  &gt;&gt;&gt; callback = tf.keras.callbacks.LearningRateScheduler(scheduler)</span>
<span class="sd">  &gt;&gt;&gt; history = model.fit(np.arange(100).reshape(5, 20), np.zeros(5),</span>
<span class="sd">  ...                     epochs=15, callbacks=[callback], verbose=0)</span>
<span class="sd">  &gt;&gt;&gt; round(model.optimizer.lr.numpy(), 5)</span>
<span class="sd">  0.00607</span>

<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">schedule</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">LearningRateScheduler</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span> <span class="o">=</span> <span class="n">schedule</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Optimizer must have a &quot;lr&quot; attribute.&#39;</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>  <span class="c1"># new API</span>
      <span class="n">lr</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">backend</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">))</span>
      <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>  <span class="c1"># Support for old API for backward compatibility</span>
      <span class="n">lr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">schedule</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The output of the &quot;schedule&quot; function &#39;</span>
                       <span class="s1">&#39;should be float.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">lr</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">is_floating</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The dtype of Tensor should be float&#39;</span><span class="p">)</span>
    <span class="n">backend</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="n">lr</span><span class="p">))</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch </span><span class="si">%05d</span><span class="s1">: LearningRateScheduler setting learning &#39;</span>
            <span class="s1">&#39;rate to </span><span class="si">%s</span><span class="s1">.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">lr</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">logs</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">keras_model_summary</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Writes a Keras model as JSON to as a Summary.</span>

<span class="sd">  Writing the Keras model configuration allows the TensorBoard graph plugin to</span>
<span class="sd">  render a conceptual graph, as opposed to graph of ops. In case the model fails</span>
<span class="sd">  to serialize as JSON, it ignores and returns False.</span>

<span class="sd">  Args:</span>
<span class="sd">    name: A name for this summary. The summary tag used for TensorBoard will be</span>
<span class="sd">      this name prefixed by any active name scopes.</span>
<span class="sd">    data: A Keras Model to write.</span>
<span class="sd">    step: Explicit `int64`-castable monotonic step value for this summary. If</span>
<span class="sd">      omitted, this defaults to `tf.summary.experimental.get_step()`, which must</span>
<span class="sd">      not be None.</span>

<span class="sd">  Returns:</span>
<span class="sd">    True on success, or False if no summary was written because no default</span>
<span class="sd">    summary writer was available.</span>

<span class="sd">  Raises:</span>
<span class="sd">    ValueError: if a default writer exists, but no step was provided and</span>
<span class="sd">      `tf.summary.experimental.get_step()` is None.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">summary_metadata</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">compat</span><span class="o">.</span><span class="n">v1</span><span class="o">.</span><span class="n">SummaryMetadata</span><span class="p">()</span>
  <span class="c1"># Hard coding a plugin name. Please refer to go/tb-plugin-name-hardcode for</span>
  <span class="c1"># the rationale.</span>
  <span class="n">summary_metadata</span><span class="o">.</span><span class="n">plugin_data</span><span class="o">.</span><span class="n">plugin_name</span> <span class="o">=</span> <span class="s1">&#39;graph_keras_model&#39;</span>
  <span class="c1"># version number = 1</span>
  <span class="n">summary_metadata</span><span class="o">.</span><span class="n">plugin_data</span><span class="o">.</span><span class="n">content</span> <span class="o">=</span> <span class="sa">b</span><span class="s1">&#39;1&#39;</span>

  <span class="k">try</span><span class="p">:</span>
    <span class="n">json_string</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to_json</span><span class="p">()</span>
  <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">exc</span><span class="p">:</span>  <span class="c1"># pylint: disable=broad-except</span>
    <span class="c1"># An exception should not break a model code.</span>
    <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Model failed to serialize as JSON. Ignoring... </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">exc</span><span class="p">)</span>
    <span class="k">return</span> <span class="kc">False</span>

  <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">summary_scope</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;graph_keras_model&#39;</span><span class="p">,</span>
                                    <span class="p">[</span><span class="n">data</span><span class="p">,</span> <span class="n">step</span><span class="p">])</span> <span class="k">as</span> <span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">_</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu:0&#39;</span><span class="p">):</span>
      <span class="n">tensor</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">json_string</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">string</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">write</span><span class="p">(</span>
        <span class="n">tag</span><span class="o">=</span><span class="n">tag</span><span class="p">,</span> <span class="n">tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="n">summary_metadata</span><span class="p">)</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.TensorBoard&#39;</span><span class="p">,</span> <span class="n">v1</span><span class="o">=</span><span class="p">[])</span>
<span class="k">class</span> <span class="nc">TensorBoard</span><span class="p">(</span><span class="n">Callback</span><span class="p">,</span> <span class="n">version_utils</span><span class="o">.</span><span class="n">TensorBoardVersionSelector</span><span class="p">):</span>
  <span class="c1"># pylint: disable=line-too-long</span>
  <span class="sd">&quot;&quot;&quot;Enable visualizations for TensorBoard.</span>

<span class="sd">  TensorBoard is a visualization tool provided with TensorFlow.</span>

<span class="sd">  This callback logs events for TensorBoard, including:</span>

<span class="sd">  * Metrics summary plots</span>
<span class="sd">  * Training graph visualization</span>
<span class="sd">  * Activation histograms</span>
<span class="sd">  * Sampled profiling</span>

<span class="sd">  When used in `Model.evaluate`, in addition to epoch summaries, there will be</span>
<span class="sd">  a summary that records evaluation metrics vs `Model.optimizer.iterations`</span>
<span class="sd">  written. The metric names will be prepended with `evaluation`, with</span>
<span class="sd">  `Model.optimizer.iterations` being the step in the visualized TensorBoard.</span>

<span class="sd">  If you have installed TensorFlow with pip, you should be able</span>
<span class="sd">  to launch TensorBoard from the command line:</span>

<span class="sd">  ```</span>
<span class="sd">  tensorboard --logdir=path_to_your_logs</span>
<span class="sd">  ```</span>

<span class="sd">  You can find more information about TensorBoard</span>
<span class="sd">  [here](https://www.tensorflow.org/get_started/summaries_and_tensorboard).</span>

<span class="sd">  Args:</span>
<span class="sd">      log_dir: the path of the directory where to save the log files to be</span>
<span class="sd">        parsed by TensorBoard. e.g. log_dir = os.path.join(working_dir, &#39;logs&#39;)</span>
<span class="sd">        This directory should not be reused by any other callbacks.</span>
<span class="sd">      histogram_freq: frequency (in epochs) at which to compute activation and</span>
<span class="sd">        weight histograms for the layers of the model. If set to 0, histograms</span>
<span class="sd">        won&#39;t be computed. Validation data (or split) must be specified for</span>
<span class="sd">        histogram visualizations.</span>
<span class="sd">      write_graph: whether to visualize the graph in TensorBoard. The log file</span>
<span class="sd">        can become quite large when write_graph is set to True.</span>
<span class="sd">      write_images: whether to write model weights to visualize as image in</span>
<span class="sd">        TensorBoard.</span>
<span class="sd">      write_steps_per_second: whether to log the training steps per second into</span>
<span class="sd">        Tensorboard. This supports both epoch and batch frequency logging.</span>
<span class="sd">      update_freq: `&#39;batch&#39;` or `&#39;epoch&#39;` or integer. When using `&#39;batch&#39;`,</span>
<span class="sd">        writes the losses and metrics to TensorBoard after each batch. The same</span>
<span class="sd">        applies for `&#39;epoch&#39;`. If using an integer, let&#39;s say `1000`, the</span>
<span class="sd">        callback will write the metrics and losses to TensorBoard every 1000</span>
<span class="sd">        batches. Note that writing too frequently to TensorBoard can slow down</span>
<span class="sd">        your training.</span>
<span class="sd">      profile_batch: Profile the batch(es) to sample compute characteristics.</span>
<span class="sd">        profile_batch must be a non-negative integer or a tuple of integers.</span>
<span class="sd">        A pair of positive integers signify a range of batches to profile.</span>
<span class="sd">        By default, it will profile the second batch. Set profile_batch=0</span>
<span class="sd">        to disable profiling.</span>
<span class="sd">      embeddings_freq: frequency (in epochs) at which embedding layers will be</span>
<span class="sd">        visualized. If set to 0, embeddings won&#39;t be visualized.</span>
<span class="sd">      embeddings_metadata: Dictionary which maps embedding layer names to the</span>
<span class="sd">        filename of a file in which to save metadata for the embedding layer.</span>
<span class="sd">        In case the same metadata file is to be</span>
<span class="sd">        used for all embedding layers, a single filename can be passed.</span>

<span class="sd">  Examples:</span>

<span class="sd">  Basic usage:</span>

<span class="sd">  ```python</span>
<span class="sd">  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=&quot;./logs&quot;)</span>
<span class="sd">  model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])</span>
<span class="sd">  # Then run the tensorboard command to view the visualizations.</span>
<span class="sd">  ```</span>

<span class="sd">  Custom batch-level summaries in a subclassed Model:</span>

<span class="sd">  ```python</span>
<span class="sd">  class MyModel(tf.keras.Model):</span>

<span class="sd">    def build(self, _):</span>
<span class="sd">      self.dense = tf.keras.layers.Dense(10)</span>

<span class="sd">    def call(self, x):</span>
<span class="sd">      outputs = self.dense(x)</span>
<span class="sd">      tf.summary.histogram(&#39;outputs&#39;, outputs)</span>
<span class="sd">      return outputs</span>

<span class="sd">  model = MyModel()</span>
<span class="sd">  model.compile(&#39;sgd&#39;, &#39;mse&#39;)</span>

<span class="sd">  # Make sure to set `update_freq=N` to log a batch-level summary every N batches.</span>
<span class="sd">  # In addition to any `tf.summary` contained in `Model.call`, metrics added in</span>
<span class="sd">  # `Model.compile` will be logged every N batches.</span>
<span class="sd">  tb_callback = tf.keras.callbacks.TensorBoard(&#39;./logs&#39;, update_freq=1)</span>
<span class="sd">  model.fit(x_train, y_train, callbacks=[tb_callback])</span>
<span class="sd">  ```</span>

<span class="sd">  Custom batch-level summaries in a Functional API Model:</span>

<span class="sd">  ```python</span>
<span class="sd">  def my_summary(x):</span>
<span class="sd">    tf.summary.histogram(&#39;x&#39;, x)</span>
<span class="sd">    return x</span>

<span class="sd">  inputs = tf.keras.Input(10)</span>
<span class="sd">  x = tf.keras.layers.Dense(10)(inputs)</span>
<span class="sd">  outputs = tf.keras.layers.Lambda(my_summary)(x)</span>
<span class="sd">  model = tf.keras.Model(inputs, outputs)</span>
<span class="sd">  model.compile(&#39;sgd&#39;, &#39;mse&#39;)</span>

<span class="sd">  # Make sure to set `update_freq=N` to log a batch-level summary every N batches.</span>
<span class="sd">  # In addition to any `tf.summary` contained in `Model.call`, metrics added in</span>
<span class="sd">  # `Model.compile` will be logged every N batches.</span>
<span class="sd">  tb_callback = tf.keras.callbacks.TensorBoard(&#39;./logs&#39;, update_freq=1)</span>
<span class="sd">  model.fit(x_train, y_train, callbacks=[tb_callback])</span>
<span class="sd">  ```</span>

<span class="sd">  Profiling:</span>

<span class="sd">  ```python</span>
<span class="sd">  # Profile a single batch, e.g. the 5th batch.</span>
<span class="sd">  tensorboard_callback = tf.keras.callbacks.TensorBoard(</span>
<span class="sd">      log_dir=&#39;./logs&#39;, profile_batch=5)</span>
<span class="sd">  model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])</span>

<span class="sd">  # Profile a range of batches, e.g. from 10 to 20.</span>
<span class="sd">  tensorboard_callback = tf.keras.callbacks.TensorBoard(</span>
<span class="sd">      log_dir=&#39;./logs&#39;, profile_batch=(10,20))</span>
<span class="sd">  model.fit(x_train, y_train, epochs=2, callbacks=[tensorboard_callback])</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="c1"># pylint: enable=line-too-long</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">log_dir</span><span class="o">=</span><span class="s1">&#39;logs&#39;</span><span class="p">,</span>
               <span class="n">histogram_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">write_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
               <span class="n">write_images</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">write_steps_per_second</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">update_freq</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span>
               <span class="n">profile_batch</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
               <span class="n">embeddings_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">embeddings_metadata</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">TensorBoard</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_supports_tf_logs</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_validate_kwargs</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span> <span class="o">=</span> <span class="n">path_to_string</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">histogram_freq</span> <span class="o">=</span> <span class="n">histogram_freq</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">write_graph</span> <span class="o">=</span> <span class="n">write_graph</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">write_images</span> <span class="o">=</span> <span class="n">write_images</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">write_steps_per_second</span> <span class="o">=</span> <span class="n">write_steps_per_second</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">update_freq</span> <span class="o">==</span> <span class="s1">&#39;batch&#39;</span> <span class="k">else</span> <span class="n">update_freq</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span> <span class="o">=</span> <span class="n">embeddings_freq</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span> <span class="o">=</span> <span class="n">embeddings_metadata</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_init_profile_batch</span><span class="p">(</span><span class="n">profile_batch</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_global_train_batch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_previous_epoch_iterations</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_train_accumulated_time</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_time</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Lazily initialized in order to avoid creating event files when</span>
    <span class="c1"># not needed.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="c1"># Used to restore any existing `SummaryWriter` after training ends.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_prev_summary_state</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">def</span> <span class="nf">_validate_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Handle arguments were supported in V1.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;write_grads&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`write_grads` will be ignored in TensorFlow 2.0 &#39;</span>
                      <span class="s1">&#39;for the `TensorBoard` Callback.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;batch_size&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`batch_size` is no longer needed in the &#39;</span>
                      <span class="s1">&#39;`TensorBoard` Callback and will be ignored &#39;</span>
                      <span class="s1">&#39;in TensorFlow 2.0.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;embeddings_layer_names&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`embeddings_layer_names` is not supported in &#39;</span>
                      <span class="s1">&#39;TensorFlow 2.0. Instead, all `Embedding` layers &#39;</span>
                      <span class="s1">&#39;will be visualized.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;embeddings_data&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`embeddings_data` is not supported in TensorFlow &#39;</span>
                      <span class="s1">&#39;2.0. Instead, all `Embedding` variables will be &#39;</span>
                      <span class="s1">&#39;visualized.&#39;</span><span class="p">)</span>

    <span class="n">unrecognized_kwargs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">kwargs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">-</span> <span class="p">{</span>
        <span class="s1">&#39;write_grads&#39;</span><span class="p">,</span> <span class="s1">&#39;embeddings_layer_names&#39;</span><span class="p">,</span> <span class="s1">&#39;embeddings_data&#39;</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span>
    <span class="p">}</span>

    <span class="c1"># Only allow kwargs that were supported in V1.</span>
    <span class="k">if</span> <span class="n">unrecognized_kwargs</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unrecognized arguments in `TensorBoard` &#39;</span>
                       <span class="s1">&#39;Callback: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">unrecognized_kwargs</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets Keras model and writes graph if specified.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_log_write_dir</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_log_write_dir</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_train_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_write_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_train_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_train_counter</span>  <span class="c1"># pylint: disable=protected-access</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_val_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_write_dir</span><span class="p">,</span> <span class="s1">&#39;validation&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_val_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_test_counter</span>  <span class="c1"># pylint: disable=protected-access</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Resets writers.</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_should_write_train_graph</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_graph</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_write_keras_model_summary</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_should_write_train_graph</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_configure_embeddings</span><span class="p">()</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_train_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="s1">&#39;train&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">create_file_writer</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">_train_dir</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">_val_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="s1">&#39;val&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">create_file_writer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_val_dir</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">_get_log_write_dir</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;For multi-worker, only chief should write, others write to &#39;/tmp&#39;.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">distributed_file_utils</span><span class="o">.</span><span class="n">write_dirpath</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span>
                                                <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_delete_tmp_write_dir</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Deletes tmp write directories for multi-worker.&quot;&quot;&quot;</span>
    <span class="n">distributed_file_utils</span><span class="o">.</span><span class="n">remove_temp_dirpath</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_dir</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">distribute_strategy</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_write_keras_model_train_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Writes Keras model train_function graph to TensorBoard.&quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">record_if</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">train_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train_tf_function</span>
        <span class="c1"># If the train_function is a `tf.function`, we can write out a graph</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">train_fn</span><span class="p">,</span> <span class="s1">&#39;function_spec&#39;</span><span class="p">):</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">graph</span><span class="p">(</span><span class="n">train_fn</span><span class="o">.</span><span class="n">_concrete_stateful_fn</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>

  <span class="k">def</span> <span class="nf">_write_keras_model_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Writes Keras graph network summary to TensorBoard.&quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">record_if</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">summary_writable</span> <span class="o">=</span> <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">_is_graph_network</span> <span class="ow">or</span>  <span class="c1"># pylint: disable=protected-access</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;Sequential&#39;</span><span class="p">)</span>  <span class="c1"># pylint: disable=protected-access</span>
        <span class="k">if</span> <span class="n">summary_writable</span><span class="p">:</span>
          <span class="n">keras_model_summary</span><span class="p">(</span><span class="s1">&#39;keras&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_configure_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Configure the Projector for embeddings.&quot;&quot;&quot;</span>
    <span class="c1"># TODO(omalleyt): Add integration tests.</span>
    <span class="kn">from</span> <span class="nn">google.protobuf</span> <span class="kn">import</span> <span class="n">text_format</span>
    <span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">embeddings</span>
    <span class="kn">from</span> <span class="nn">keras.protobuf</span> <span class="kn">import</span> <span class="n">projector_config_pb2</span>

    <span class="n">config</span> <span class="o">=</span> <span class="n">projector_config_pb2</span><span class="o">.</span><span class="n">ProjectorConfig</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">Embedding</span><span class="p">):</span>
        <span class="n">embedding</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">add</span><span class="p">()</span>
        <span class="c1"># Embeddings are always the first layer, so this naming should be</span>
        <span class="c1"># consistent in any keras models checkpoints.</span>
        <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;layer_with_weights-0/embeddings/.ATTRIBUTES/VARIABLE_VALUE&#39;</span>
        <span class="n">embedding</span><span class="o">.</span><span class="n">tensor_name</span> <span class="o">=</span> <span class="n">name</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
          <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">embedding</span><span class="o">.</span><span class="n">metadata_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span>
          <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
              <span class="n">embedding</span><span class="o">.</span><span class="n">metadata_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="p">,</span>
                                                   <span class="nb">str</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Unrecognized `Embedding` layer names passed to &#39;</span>
                       <span class="s1">&#39;`keras.callbacks.TensorBoard` `embeddings_metadata` &#39;</span>
                       <span class="s1">&#39;argument: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embeddings_metadata</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>

    <span class="n">config_pbtxt</span> <span class="o">=</span> <span class="n">text_format</span><span class="o">.</span><span class="n">MessageToString</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_write_dir</span><span class="p">,</span> <span class="s1">&#39;projector_config.pbtxt&#39;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">GFile</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
      <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">config_pbtxt</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_push_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">writer</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sets the default writer for custom batch-level summaries.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">==</span> <span class="s1">&#39;epoch&#39;</span><span class="p">:</span>
      <span class="k">return</span>

    <span class="n">should_record</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">step</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="c1"># TODO(b/151339474): Fix deadlock when not using .value() here.</span>
    <span class="n">summary_context</span> <span class="o">=</span> <span class="p">(</span><span class="n">writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">(</span><span class="n">step</span><span class="o">.</span><span class="n">value</span><span class="p">()),</span>
                       <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">record_if</span><span class="p">(</span><span class="n">should_record</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_prev_summary_state</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">summary_context</span><span class="p">)</span>
    <span class="n">summary_context</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="fm">__enter__</span><span class="p">()</span>
    <span class="n">summary_context</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="fm">__enter__</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_pop_writer</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pops the current writer.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_freq</span> <span class="o">==</span> <span class="s1">&#39;epoch&#39;</span><span class="p">:</span>
      <span class="k">return</span>

    <span class="c1"># See _push_writer for the content of the previous_context, which is pair</span>
    <span class="c1"># of context.</span>
    <span class="n">previous_context</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_prev_summary_state</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
    <span class="n">previous_context</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span><span class="o">*</span><span class="n">sys</span><span class="o">.</span><span class="n">exc_info</span><span class="p">())</span>
    <span class="n">previous_context</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="fm">__exit__</span><span class="p">(</span><span class="o">*</span><span class="n">sys</span><span class="o">.</span><span class="n">exc_info</span><span class="p">())</span>

  <span class="k">def</span> <span class="nf">_close_writers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">writer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_writers</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
      <span class="n">writer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_init_profile_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">profile_batch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Validate profile_batch value and set the range of batches to profile.</span>
<span class="sd">    Sets values of _start_batch and _stop_batch attributes,</span>
<span class="sd">    specifying the start and stop batch to profile.</span>
<span class="sd">    Setting `profile_batch=0` disables profiling.</span>

<span class="sd">    Args:</span>
<span class="sd">      profile_batch: The range of batches to profile. Should be a non-negative</span>
<span class="sd">        integer or a comma separated string of pair of positive integers. A pair</span>
<span class="sd">        of positive integers signify a range of batches to profile.</span>

<span class="sd">    Raises:</span>
<span class="sd">      ValueError: If profile_batch is not an integer or a comma seperated pair</span>
<span class="sd">                  of positive integers.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">profile_batch_error_message</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s1">&#39;profile_batch must be a non-negative integer or 2-tuple of positive &#39;</span>
        <span class="s1">&#39;integers. A pair of positive integers signifies a range of batches &#39;</span>
        <span class="s1">&#39;to profile. Found: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">profile_batch</span><span class="p">))</span>

    <span class="c1"># Support legacy way of specifying &quot;start,stop&quot; or &quot;start&quot; as str.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">profile_batch</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
      <span class="n">profile_batch</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">profile_batch</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
      <span class="n">profile_batch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nest</span><span class="o">.</span><span class="n">map_structure</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">profile_batch</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">profile_batch</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_start_batch</span> <span class="o">=</span> <span class="n">profile_batch</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_stop_batch</span> <span class="o">=</span> <span class="n">profile_batch</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">profile_batch</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">profile_batch</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_start_batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stop_batch</span> <span class="o">=</span> <span class="n">profile_batch</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">profile_batch_error_message</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_start_batch</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stop_batch</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_start_batch</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">profile_batch_error_message</span><span class="p">)</span>

    <span class="c1"># True when the profiler was successfully started by this callback.</span>
    <span class="c1"># We track the status here to make sure callbacks do not interfere with</span>
    <span class="c1"># each other. The callback will only stop the profiler it started.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_profiler_started</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_start_batch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
      <span class="c1"># Warm up and improve the profiling accuracy.</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_start_profiler</span><span class="p">(</span><span class="n">logdir</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_stop_profiler</span><span class="p">(</span><span class="n">save</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># True when a trace is running.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Setting `profile_batch=0` disables profiling.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_should_trace</span> <span class="o">=</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_start_batch</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stop_batch</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_global_train_batch</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_previous_epoch_iterations</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_train_accumulated_time</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_push_writer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_writer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_step</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_pop_writer</span><span class="p">()</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_stop_trace</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">_close_writers</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_delete_tmp_write_dir</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_test_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_push_writer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_val_writer</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_step</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_test_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;iterations&#39;</span><span class="p">):</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">record_if</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
          <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span>
              <span class="s1">&#39;evaluation_&#39;</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_vs_iterations&#39;</span><span class="p">,</span>
              <span class="n">value</span><span class="p">,</span>
              <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">iterations</span><span class="o">.</span><span class="n">read_value</span><span class="p">())</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_pop_writer</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_implements_train_batch_hooks</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Only call batch hooks when tracing or write_steps_per_second are enabled</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_trace</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_steps_per_second</span>

  <span class="k">def</span> <span class="nf">on_train_batch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_global_train_batch</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_steps_per_second</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_trace</span><span class="p">:</span>
      <span class="k">return</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_train_batch</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_start_batch</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_start_trace</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_train_batch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_write_train_graph</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_write_keras_model_train_graph</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_should_write_train_graph</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_steps_per_second</span><span class="p">:</span>
      <span class="n">batch_run_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_batch_start_time</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_train_accumulated_time</span> <span class="o">+=</span> <span class="n">batch_run_time</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span>
          <span class="s1">&#39;batch_steps_per_second&#39;</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">batch_run_time</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_step</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_should_trace</span><span class="p">:</span>
      <span class="k">return</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_train_batch</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stop_batch</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_stop_trace</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_epoch_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># Keeps track of epoch for profiling.</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_steps_per_second</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_previous_epoch_iterations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">iterations</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_train_accumulated_time</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Runs metrics and histogram summaries at epoch end.&quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_log_epoch_metrics</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">histogram_freq</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">histogram_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_log_weights</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span> <span class="ow">and</span> <span class="n">epoch</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">embeddings_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_log_embeddings</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_start_trace</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">trace_on</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">profiler</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_start_profiler</span><span class="p">(</span><span class="n">logdir</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_dir</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="k">def</span> <span class="nf">_stop_trace</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Logs the trace graph to TensorBoard.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">batch</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stop_batch</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">record_if</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
        <span class="c1"># TODO(b/126388999): Remove step info in the summary name.</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">trace_export</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;batch_</span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">batch</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">batch</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_stop_profiler</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_is_tracing</span> <span class="o">=</span> <span class="kc">False</span>

  <span class="k">def</span> <span class="nf">_collect_learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="n">lr_schedule</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;lr&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">lr_schedule</span><span class="p">,</span> <span class="n">learning_rate_schedule</span><span class="o">.</span><span class="n">LearningRateSchedule</span><span class="p">):</span>
      <span class="n">logs</span><span class="p">[</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lr_schedule</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">iterations</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">logs</span>

  <span class="k">def</span> <span class="nf">_compute_steps_per_second</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">current_iteration</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">iterations</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">steps_per_second</span> <span class="o">=</span> <span class="p">((</span><span class="n">current_iteration</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_previous_epoch_iterations</span><span class="p">)</span> <span class="o">/</span>
                        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_accumulated_time</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">steps_per_second</span>

  <span class="k">def</span> <span class="nf">_log_epoch_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Writes epoch metrics out as scalar summaries.</span>

<span class="sd">    Args:</span>
<span class="sd">        epoch: Int. The global step to use for TensorBoard.</span>
<span class="sd">        logs: Dict. Keys are scalar summary names, values are scalars.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">logs</span><span class="p">:</span>
      <span class="k">return</span>

    <span class="n">train_logs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;val_&#39;</span><span class="p">)}</span>
    <span class="n">val_logs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">logs</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;val_&#39;</span><span class="p">)}</span>
    <span class="n">train_logs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_collect_learning_rate</span><span class="p">(</span><span class="n">train_logs</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_steps_per_second</span><span class="p">:</span>
      <span class="n">train_logs</span><span class="p">[</span><span class="s1">&#39;steps_per_second&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_steps_per_second</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">record_if</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
      <span class="k">if</span> <span class="n">train_logs</span><span class="p">:</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
          <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">train_logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;epoch_&#39;</span> <span class="o">+</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">val_logs</span><span class="p">:</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
          <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">val_logs</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">[</span><span class="mi">4</span><span class="p">:]</span>  <span class="c1"># Remove &#39;val_&#39; prefix.</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">scalar</span><span class="p">(</span><span class="s1">&#39;epoch_&#39;</span> <span class="o">+</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_log_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Logs the weights of the Model to TensorBoard.&quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_train_writer</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
      <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">record_if</span><span class="p">(</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
          <span class="k">for</span> <span class="n">weight</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">weights</span><span class="p">:</span>
            <span class="n">weight_name</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="s1">&#39;_&#39;</span><span class="p">)</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">weight_name</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">write_images</span><span class="p">:</span>
              <span class="bp">self</span><span class="o">.</span><span class="n">_log_weight_as_image</span><span class="p">(</span><span class="n">weight</span><span class="p">,</span> <span class="n">weight_name</span><span class="p">,</span> <span class="n">epoch</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_train_writer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_log_weight_as_image</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weight</span><span class="p">,</span> <span class="n">weight_name</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Logs a weight as a TensorBoard image.&quot;&quot;&quot;</span>
    <span class="n">w_img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Bias case</span>
      <span class="n">w_img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>  <span class="c1"># Dense layer kernel case</span>
      <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">w_img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
      <span class="n">w_img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>  <span class="c1"># ConvNet case</span>
      <span class="k">if</span> <span class="n">backend</span><span class="o">.</span><span class="n">image_data_format</span><span class="p">()</span> <span class="o">==</span> <span class="s1">&#39;channels_last&#39;</span><span class="p">:</span>
        <span class="c1"># Switch to channels_first to display every kernel as a separate</span>
        <span class="c1"># image.</span>
        <span class="n">w_img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
      <span class="n">w_img</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">w_img</span><span class="p">,</span> <span class="p">[</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="mi">1</span><span class="p">])</span>

    <span class="n">shape</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">w_img</span><span class="p">)</span>
    <span class="c1"># Not possible to handle 3D convnets etc.</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span> <span class="ow">and</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">summary</span><span class="o">.</span><span class="n">image</span><span class="p">(</span><span class="n">weight_name</span><span class="p">,</span> <span class="n">w_img</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">epoch</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_log_embeddings</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">):</span>
    <span class="n">embeddings_ckpt</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_log_write_dir</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span>
                                   <span class="s1">&#39;keras_embedding.ckpt-</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="n">embeddings_ckpt</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_start_profiler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logdir</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Starts the profiler if currently inactive.</span>

<span class="sd">    Args:</span>
<span class="sd">      logdir: Directory where profiler results will be saved.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_profiler_started</span><span class="p">:</span>
      <span class="k">return</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="n">logdir</span><span class="o">=</span><span class="n">logdir</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_profiler_started</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">except</span> <span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">AlreadyExistsError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="c1"># Profiler errors should not be fatal.</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s1">&#39;Failed to start profiler: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">e</span><span class="o">.</span><span class="n">message</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">_stop_profiler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">save</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Stops the profiler if currently active.</span>

<span class="sd">    Args:</span>
<span class="sd">      save: Whether to save the profiler results to TensorBoard.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_profiler_started</span><span class="p">:</span>
      <span class="k">return</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">stop</span><span class="p">(</span><span class="n">save</span><span class="o">=</span><span class="n">save</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">UnavailableError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
      <span class="c1"># Profiler errors should not be fatal.</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s1">&#39;Failed to stop profiler: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">e</span><span class="o">.</span><span class="n">message</span><span class="p">)</span>
    <span class="k">finally</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">_profiler_started</span> <span class="o">=</span> <span class="kc">False</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.ReduceLROnPlateau&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">ReduceLROnPlateau</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Reduce learning rate when a metric has stopped improving.</span>

<span class="sd">  Models often benefit from reducing the learning rate by a factor</span>
<span class="sd">  of 2-10 once learning stagnates. This callback monitors a</span>
<span class="sd">  quantity and if no improvement is seen for a &#39;patience&#39; number</span>
<span class="sd">  of epochs, the learning rate is reduced.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  reduce_lr = ReduceLROnPlateau(monitor=&#39;val_loss&#39;, factor=0.2,</span>
<span class="sd">                                patience=5, min_lr=0.001)</span>
<span class="sd">  model.fit(X_train, Y_train, callbacks=[reduce_lr])</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">      monitor: quantity to be monitored.</span>
<span class="sd">      factor: factor by which the learning rate will be reduced.</span>
<span class="sd">        `new_lr = lr * factor`.</span>
<span class="sd">      patience: number of epochs with no improvement after which learning rate</span>
<span class="sd">        will be reduced.</span>
<span class="sd">      verbose: int. 0: quiet, 1: update messages.</span>
<span class="sd">      mode: one of `{&#39;auto&#39;, &#39;min&#39;, &#39;max&#39;}`. In `&#39;min&#39;` mode,</span>
<span class="sd">        the learning rate will be reduced when the</span>
<span class="sd">        quantity monitored has stopped decreasing; in `&#39;max&#39;` mode it will be</span>
<span class="sd">        reduced when the quantity monitored has stopped increasing; in `&#39;auto&#39;`</span>
<span class="sd">        mode, the direction is automatically inferred from the name of the</span>
<span class="sd">        monitored quantity.</span>
<span class="sd">      min_delta: threshold for measuring the new optimum, to only focus on</span>
<span class="sd">        significant changes.</span>
<span class="sd">      cooldown: number of epochs to wait before resuming normal operation after</span>
<span class="sd">        lr has been reduced.</span>
<span class="sd">      min_lr: lower bound on the learning rate.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span>
               <span class="n">factor</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
               <span class="n">patience</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
               <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span>
               <span class="n">min_delta</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
               <span class="n">cooldown</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="n">min_lr</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ReduceLROnPlateau</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span> <span class="o">=</span> <span class="n">monitor</span>
    <span class="k">if</span> <span class="n">factor</span> <span class="o">&gt;=</span> <span class="mf">1.0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;ReduceLROnPlateau &#39;</span> <span class="s1">&#39;does not support a factor &gt;= 1.0.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="s1">&#39;epsilon&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
      <span class="n">min_delta</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;epsilon&#39;</span><span class="p">)</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;`epsilon` argument is deprecated and &#39;</span>
                      <span class="s1">&#39;will be removed, use `min_delta` instead.&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">factor</span> <span class="o">=</span> <span class="n">factor</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_lr</span> <span class="o">=</span> <span class="n">min_lr</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span> <span class="o">=</span> <span class="n">min_delta</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cooldown</span> <span class="o">=</span> <span class="n">cooldown</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Cooldown counter.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">_reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Resets wait counter and cooldown counter.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">]:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Learning rate reduction mode </span><span class="si">%s</span><span class="s1"> is unknown, &#39;</span>
                      <span class="s1">&#39;fallback to auto mode.&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span>
    <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;min&#39;</span> <span class="ow">or</span>
        <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;auto&#39;</span> <span class="ow">and</span> <span class="s1">&#39;acc&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)):</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_delta</span><span class="p">)</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">Inf</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_reset</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="n">logs</span><span class="p">[</span><span class="s1">&#39;lr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">current</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">current</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span><span class="s1">&#39;Learning rate reduction is conditioned on metric `</span><span class="si">%s</span><span class="s1">` &#39;</span>
                      <span class="s1">&#39;which is not available. Available metrics are: </span><span class="si">%s</span><span class="s1">&#39;</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">monitor</span><span class="p">,</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>

    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_cooldown</span><span class="p">():</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">-=</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>

      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">monitor_op</span><span class="p">(</span><span class="n">current</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">best</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">best</span> <span class="o">=</span> <span class="n">current</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>
      <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_cooldown</span><span class="p">():</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
          <span class="n">old_lr</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">)</span>
          <span class="k">if</span> <span class="n">old_lr</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">min_lr</span><span class="p">):</span>
            <span class="n">new_lr</span> <span class="o">=</span> <span class="n">old_lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">factor</span>
            <span class="n">new_lr</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">new_lr</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_lr</span><span class="p">)</span>
            <span class="n">backend</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">new_lr</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
              <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Epoch </span><span class="si">%05d</span><span class="s1">: ReduceLROnPlateau reducing learning &#39;</span>
                    <span class="s1">&#39;rate to </span><span class="si">%s</span><span class="s1">.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">new_lr</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cooldown</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">wait</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="k">def</span> <span class="nf">in_cooldown</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cooldown_counter</span> <span class="o">&gt;</span> <span class="mi">0</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.CSVLogger&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">CSVLogger</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sd">&quot;&quot;&quot;Callback that streams epoch results to a CSV file.</span>

<span class="sd">  Supports all values that can be represented as a string,</span>
<span class="sd">  including 1D iterables such as `np.ndarray`.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  csv_logger = CSVLogger(&#39;training.log&#39;)</span>
<span class="sd">  model.fit(X_train, Y_train, callbacks=[csv_logger])</span>
<span class="sd">  ```</span>

<span class="sd">  Args:</span>
<span class="sd">      filename: Filename of the CSV file, e.g. `&#39;run/log.csv&#39;`.</span>
<span class="sd">      separator: String used to separate elements in the CSV file.</span>
<span class="sd">      append: Boolean. True: append if file exists (useful for continuing</span>
<span class="sd">          training). False: overwrite existing file.</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">separator</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="n">append</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sep</span> <span class="o">=</span> <span class="n">separator</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">filename</span> <span class="o">=</span> <span class="n">path_to_string</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">append</span> <span class="o">=</span> <span class="n">append</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">keys</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">append_header</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">CSVLogger</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_train_begin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">append</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">):</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">GFile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">append_header</span> <span class="o">=</span> <span class="ow">not</span> <span class="nb">bool</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">readline</span><span class="p">()))</span>
      <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;a&#39;</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;w&#39;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">gfile</span><span class="o">.</span><span class="n">GFile</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">filename</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">logs</span> <span class="o">=</span> <span class="n">logs</span> <span class="ow">or</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">handle_value</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
      <span class="n">is_zero_dim_ndarray</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">and</span> <span class="n">k</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span>
      <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">k</span>
      <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">abc</span><span class="o">.</span><span class="n">Iterable</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">is_zero_dim_ndarray</span><span class="p">:</span>
        <span class="k">return</span> <span class="s1">&#39;&quot;[</span><span class="si">%s</span><span class="s1">]&quot;&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">str</span><span class="p">,</span> <span class="n">k</span><span class="p">)))</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">k</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">keys</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">logs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">stop_training</span><span class="p">:</span>
      <span class="c1"># We set NA so that csv parsers do not fail for this last epoch.</span>
      <span class="n">logs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">((</span><span class="n">k</span><span class="p">,</span> <span class="n">logs</span><span class="p">[</span><span class="n">k</span><span class="p">])</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">logs</span> <span class="k">else</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="s1">&#39;NA&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="p">:</span>

      <span class="k">class</span> <span class="nc">CustomDialect</span><span class="p">(</span><span class="n">csv</span><span class="o">.</span><span class="n">excel</span><span class="p">):</span>
        <span class="n">delimiter</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sep</span>

      <span class="n">fieldnames</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span>

      <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictWriter</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span><span class="p">,</span>
          <span class="n">fieldnames</span><span class="o">=</span><span class="n">fieldnames</span><span class="p">,</span>
          <span class="n">dialect</span><span class="o">=</span><span class="n">CustomDialect</span><span class="p">)</span>
      <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">append_header</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">writeheader</span><span class="p">()</span>

    <span class="n">row_dict</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">OrderedDict</span><span class="p">({</span><span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">})</span>
    <span class="n">row_dict</span><span class="o">.</span><span class="n">update</span><span class="p">((</span><span class="n">key</span><span class="p">,</span> <span class="n">handle_value</span><span class="p">(</span><span class="n">logs</span><span class="p">[</span><span class="n">key</span><span class="p">]))</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">keys</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="n">row_dict</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">on_train_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">csv_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">writer</span> <span class="o">=</span> <span class="kc">None</span>


<span class="nd">@keras_export</span><span class="p">(</span><span class="s1">&#39;keras.callbacks.LambdaCallback&#39;</span><span class="p">)</span>
<span class="k">class</span> <span class="nc">LambdaCallback</span><span class="p">(</span><span class="n">Callback</span><span class="p">):</span>
  <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Callback for creating simple, custom callbacks on-the-fly.</span>

<span class="sd">  This callback is constructed with anonymous functions that will be called</span>
<span class="sd">  at the appropriate time (during `Model.{fit | evaluate | predict}`).</span>
<span class="sd">  Note that the callbacks expects positional arguments, as:</span>

<span class="sd">  - `on_epoch_begin` and `on_epoch_end` expect two positional arguments:</span>
<span class="sd">    `epoch`, `logs`</span>
<span class="sd">  - `on_batch_begin` and `on_batch_end` expect two positional arguments:</span>
<span class="sd">    `batch`, `logs`</span>
<span class="sd">  - `on_train_begin` and `on_train_end` expect one positional argument:</span>
<span class="sd">    `logs`</span>

<span class="sd">  Args:</span>
<span class="sd">      on_epoch_begin: called at the beginning of every epoch.</span>
<span class="sd">      on_epoch_end: called at the end of every epoch.</span>
<span class="sd">      on_batch_begin: called at the beginning of every batch.</span>
<span class="sd">      on_batch_end: called at the end of every batch.</span>
<span class="sd">      on_train_begin: called at the beginning of model training.</span>
<span class="sd">      on_train_end: called at the end of model training.</span>

<span class="sd">  Example:</span>

<span class="sd">  ```python</span>
<span class="sd">  # Print the batch number at the beginning of every batch.</span>
<span class="sd">  batch_print_callback = LambdaCallback(</span>
<span class="sd">      on_batch_begin=lambda batch,logs: print(batch))</span>

<span class="sd">  # Stream the epoch loss to a file in JSON format. The file content</span>
<span class="sd">  # is not well-formed JSON but rather has a JSON object per line.</span>
<span class="sd">  import json</span>
<span class="sd">  json_log = open(&#39;loss_log.json&#39;, mode=&#39;wt&#39;, buffering=1)</span>
<span class="sd">  json_logging_callback = LambdaCallback(</span>
<span class="sd">      on_epoch_end=lambda epoch, logs: json_log.write(</span>
<span class="sd">          json.dumps({&#39;epoch&#39;: epoch, &#39;loss&#39;: logs[&#39;loss&#39;]}) + &#39;\n&#39;),</span>
<span class="sd">      on_train_end=lambda logs: json_log.close()</span>
<span class="sd">  )</span>

<span class="sd">  # Terminate some processes after having finished model training.</span>
<span class="sd">  processes = ...</span>
<span class="sd">  cleanup_callback = LambdaCallback(</span>
<span class="sd">      on_train_end=lambda logs: [</span>
<span class="sd">          p.terminate() for p in processes if p.is_alive()])</span>

<span class="sd">  model.fit(...,</span>
<span class="sd">            callbacks=[batch_print_callback,</span>
<span class="sd">                       json_logging_callback,</span>
<span class="sd">                       cleanup_callback])</span>
<span class="sd">  ```</span>
<span class="sd">  &quot;&quot;&quot;</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
               <span class="n">on_epoch_begin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">on_epoch_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">on_batch_begin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">on_batch_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">on_train_begin</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="n">on_train_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
               <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">LambdaCallback</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">on_epoch_begin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_epoch_begin</span> <span class="o">=</span> <span class="n">on_epoch_begin</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_epoch_begin</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">on_epoch_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_epoch_end</span> <span class="o">=</span> <span class="n">on_epoch_end</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_epoch_end</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">on_batch_begin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_begin</span> <span class="o">=</span> <span class="n">on_batch_begin</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_begin</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">on_batch_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_end</span> <span class="o">=</span> <span class="n">on_batch_end</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_batch_end</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">batch</span><span class="p">,</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">on_train_begin</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_begin</span> <span class="o">=</span> <span class="n">on_train_begin</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_begin</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">on_train_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_end</span> <span class="o">=</span> <span class="n">on_train_end</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">on_train_end</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">logs</span><span class="p">:</span> <span class="kc">None</span>
</pre></div>

            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
    
        <li class="nav-item nav-item-0"><a href="../../index.html">pysparkdl  documentation</a> &#187;</li>

          <li class="nav-item nav-item-1"><a href="../index.html" >Module code</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">keras.callbacks</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2016, Timothy Hunter and Joseph Bradley.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 3.5.1.
    </div>
  </body>
</html>